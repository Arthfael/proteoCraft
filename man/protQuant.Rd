% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/protQuant.R
\name{protQuant}
\alias{protQuant}
\title{protQuant}
\usage{
protQuant(
  Prot,
  Pep,
  pg_PepIDs = "Peptide IDs",
  pg_PepIDs_unique = "Unique peptide IDs",
  pep_IDs = "id",
  N_unique,
  LFQ_algo = "limpa",
  reScaling,
  topN_correct = TRUE,
  minN = 1,
  maxN = 50,
  LM_fun = "median",
  Weights,
  useIntWeights = FALSE,
  Priority = "Intensities",
  skipRatios = FALSE,
  expMap,
  expMap_Samples_col = "Sample",
  refGroups,
  ratGroups,
  param,
  aggrMap,
  aggrList,
  aggrNames,
  pepInt_Root,
  pepRat_root,
  pepInt_log = FALSE,
  pepRat_log = 2,
  protLFQ_toLog = TRUE,
  protRat_toLog = TRUE,
  mods_to_Exclude,
  mod_Seq = "Modified sequence",
  discard_unmod = TRUE,
  prim_Seq = "Sequence (1st accession)",
  ref_Mode = "2",
  cl,
  N.clust,
  N.reserved = 1
)
}
\arguments{
\item{Prot}{Protein/Protein groups table. A data.frame, which must contain at least peptides IDs and primary sequence of the first accession in each group.}

\item{Pep}{Peptides table. A data.frame. If it contains unmodified sequences then these are expected to be in column name "Sequence". Argument mod_Seq controls the name of the column used for modified sequence.}

\item{pg_PepIDs}{Name of the Protein/Protein groups table's peptide IDs column. Default = "Peptide IDs"}

\item{pg_PepIDs_unique}{Used only if mode = "PreferUnique". Name of the Protein/Protein groups table's unique peptide IDs column. Default = "Unique peptide IDs"}

\item{pep_IDs}{The name of the Peptides table's IDs column. Default = "id"}

\item{N_unique}{Logical or numeric. If FALSE or 0, the function just uses the "pg_PepIDs" argument. If non null (default), a second column name of unique peptide IDs should be provided using the "pg_PepIDs_unique" argument. If at least N_unique unique peptides are present, then only those will be used for quantitation, otherwise as many razor/shared peptides as necessary will be added (sorted by decreasing average intensities).}

\item{LFQ_algo}{Algorithm used to compute average profiles. One of:\cr
 - "LM": Levenberg-Marquardt method (backend = minpack.lm::nls.lm()); very similar to MaxLFQ. Normalized peptide relative profiles are aligned using Levenberg-Marquardt then summarized.\cr
 - "iq": iq's fast implementation of MaxLFQ, backend = iq::fast_MaxLFQ()\cr
 - "limpa" or "DPC": backend = limpa::dpcQuant(); current default\cr
 - "QFeatures": backend = QFeatures::aggregateFeatures()\cr
Note that limpa and QFeatures do not "just produce quantitative values": both output specific objects with additional information which can be used for downstream analysis (respectively with limma or msqrob2).\cr}

\item{reScaling}{Optional summary method for re-scaling. May be one of:\cr
- "median",\cr
- "mean",\cr
- "weighted.mean" (requires the "Weights" argument),\cr
- "max",\cr
- "sum" (not recommended),\cr
- "MaxLFQ": like sum, but the value used is the value before any peptides are filtered out (not recommended),\cr
- "topN", where N should be the maximum number of peptides to average (e.g. "top3" - do not use "topN" as there is no default value for N!)
- the name of any valid value of LFQ_algo, which allows re-scaling any LFQ algorithm using the scaling provided by another.
- (you could also use the name of any other available averaging function, this should work in principle assuming similar syntax)}

\item{topN_correct}{Logical, default = TRUE. In the case where we are using more than one peptide for the re-scaling step, should we correct for systematic peptide intensity biases between peptides of rank 1, 2, 3 and so on and so forth?}

\item{minN}{Integer, default = 1. How many peptides should at least be present for quantitation? Values lower than 1 are increased to 1. May not be higher than N_unique!}

\item{maxN}{Integer or Inf, default = 50. Up to how many peptides should we use for the Levenberg-Marquardt procedure (used only for LFQs)? Using too many peptides can be an issue, e.g. with huge proteins like Titin. Default = 50. The most intense peptides will be selected. May not be lower than N_unique!}

\item{LM_fun}{How should normalized profiles be averaged? One of "median" (default), "mean", or "weighted.mean" (the latter which uses the Weights and useIntWeights arguments).}

\item{Weights}{Length 1 character, a valid column name of Pep containing user-defined individual peptide weights. Used if LM_fun or reScaling are set to "weighted.mean" (for the former only if LFQ_algo = "LM").}

\item{useIntWeights}{Logical, default = FALSE. Ignored unless LM_fun or reScaling are set to "mean" or "weighted.mean". If TRUE, will take into account individual peptide intensities when calculating average profile for that step (thus, it will actually be a weighted mean regardless). DOES NOT replace the optional, user-provided Weights, but instead multiplies the former by new intensity-based factors.}

\item{Priority}{One of "Intensities" (default) or "Ratios" (some flexibility in spelling is allowed). In some rare cases, such as a SILAC dataset processed with MaxQuant, we will want to correct intensities - prior to running the main algorithm - so their ratios reflect the more accurate ratios directly measured by the search engine.}

\item{skipRatios}{Default = FALSE. If TRUE, ratios will not be calculated.}

\item{expMap}{Map of the experiment map.}

\item{expMap_Samples_col}{Names of the single samples column in the experiment's map. Default = "Sample"}

\item{refGroups}{Only needed if ratios (logFCs) are also to be output. List defining which samples are paired to which references. May alternatively (preferred solution) be provided indirectly through the param argument.}

\item{ratGroups}{Only needed if ratios (logFCs) are also to be output. List defining groups within which ratios are calculated. May alternatively (preferred solution) be provided indirectly through the param argument.}

\item{param}{This analysis' parameters. If provided, the refGroups argument is not required.}

\item{aggrMap}{Only needed if ratios (logFCs) are also to be output, lternative way of defining groups when Param is missing. The analysis' aggregate map. Default = Aggregate.map}

\item{aggrList}{Only needed if ratios (logFCs) are also to be output, lternative way of defining groups when Param is missing. Named list of this analysis' factors aggrNames. Default = Aggregate.list}

\item{aggrNames}{Only needed if ratios (logFCs) are also to be output, lternative way of defining groups when Param is missing. The experiment's factor aggrNames. Default = Aggregates}

\item{pepInt_Root}{Root of the peptides intensity column(s) names}

\item{pepRat_root}{Only needed if ratios (logFCs) are also to be output. Root of the peptides ratios column(s) names, used if Priority = "Ratios".}

\item{pepInt_log}{Set to 0 or FALSE if input peptide intensities are linear scale. If the data is already log scale, set to the relevant scale's base. Default = FALSE}

\item{pepRat_log}{Only needed if ratios (logFCs) are also to be output. Set to 0 or FALSE if input peptide ratios are linear scale. If the data is already log scale, set to the relevant scale's base. Default = 2}

\item{protLFQ_toLog}{Should the output protein LFQ values be log-scale or not? Can ve set to the log base desired. If set to TRUE, this will be the same base as the input intensities log scale, or 10 by default.}

\item{protRat_toLog}{Only needed if ratios (logFCs) are also to be output. Should the output protein ratios be log-scale or not? Can ve set to the log base desired. If set to TRUE, this will be the same base as the input ratios log scale, or its default, 2}

\item{mods_to_Exclude}{Which modifications should be excluded? (use argument "discard_unmod" to discard unmodified counterpart peptides.) A data.frame with columns "Mark" (2-lettern modification mark) and "Where" (a list, which amino acids are affected, use "Nterm", "Cterm", "protNterm" and "protCterm" for termini). Also see argument "discard_unmod".}

\item{mod_Seq}{Default = "Modified sequence". The name of the column containing the modified sequence in the peptides table. Can be set to a non-modified sequence if mods_to_Exclude is empty.}

\item{discard_unmod}{Logical or integer in 0:2. Default = TRUE. Should we discard those unmodified peptides whose primary sequence is the same as that of some modified peptides we will not use? If set to 2, will use the "Where" column in "mods_to_Exclude" to identify (and exclude) peptides which could be modified even if the modified form was not identified. Requires knowledge of protein sequence ("prim_Seq" argument)! Be careful! This will likely massively reduce the number of peptides available for quantitation!}

\item{prim_Seq}{Default = "Sequence (1st accession)", used if "discard_unmod" is set to 2.}

\item{ref_Mode}{How are reference ratios calculated?\cr
- If set to "1", only references are considered (i.e. it compares individual references either to each other, or if available to the average reference for the group).\cr
- If set to "2" (default), for each ratios group, reference ratios are based on comparing every possible pair of samples within the group.\cr}

\item{cl}{Already have a cluster handy? Why spend time making a new one, which on top of that may invalidate the old one. Just pass it along!}

\item{N.clust}{A limit on the number of vCPUs to use. If left as NULL (default), uses the number of available clusters - 1, to a minimum of 1.}

\item{N.reserved}{Default = 1. Number of reserved vCPUs the function is not to use. Note that for obvious reasons it will always use at least one.

#' @details
This function is meant to work from normalised peptide intensities and:\cr
 - calculates a quantitative profile for each protein,\cr
 - maximizes the usage of peptides-level ratios information.\cr
Specifically, it can be broken down into 3 sub-steps:\cr
  a) filtering peptides eligible for quantitation\cr
  b) calculating a relative protein profile across samples:\cr
   - LM: this uses Levenberg-Marquardt to align peptide profiles, then summarizes them, and is broadly similar to MaxLFQ.\cr
   - iq: the iq package's implementation of MaxLFQ, specifically the iq::fast_MaxLFQ() function.\cr
   - limpa: uses the recently introduced limpa package's dpcQuant() function.
   - QFeatures: uses the QFeatures::aggregateFeatures() function.
  c) Optional re-scaling, i.e. "anchoring" the resulting relative profile to a scale value, such that different proteins are ranked relatively in a manner which - whilst imperfect because of widely different individual peptide detectabilities - would still be correct if the latter could be corrected for, or would otherwise operate under assumptions at least minimizing the expected error. See the reScaling argument.\cr
   You may also rescale any quantitation (as specified in LFQ_algo) with the scale provided by another (using the reScaling argument), thus allowing for using the relative quantitation and scaling of any two methods.
   To re-scale the same way as MaxLFQ, use "sum" - but see N.B. below!
   iBAQ - which would be the equivalent of using "sum" then dividing by the number of observable peptides, but the additional step could easily be added outside this function.
\cr
NB on re-scaling:
  The early - and still occasional - practice of summing peptide intensities to estimate protein abundance (as used in MaxLFQ) is conceptually unsound.\cr
  The intensity of a unique peptide with perfect detectability is a function of the peptide's copy number, itself originally (before losses) equal to that of the parent protein.\cr
  If detectability could be corrected for, the intensity values of all unique peptides unaffected by PTMs would be a direct unbiased estimator of parent protein copy number.\cr
  For this reason, any intensity-based protein abundance estimate much be 'homogenous' with single peptide intensities, either through peptide selection or averaging.\cr
  We prefer the topN (1 to 3) methods, which leverage the usually better data S/N ratio of higher intensity peptides, and use the values closer to the original target.\cr
  iBAQ's proposed correction of summed intensities by dividing by the number of observable peptides, seems to make little sense: if averaging, one should divide by the number of observed, not observable, values. Hence why this is not implemented.\cr
  
\cr
\cr
(Note on refGroups and ratGroups:\cr
 These parameters are the method we used for calculating logFCs and together define whether replicates are paired or not.\cr
 For an experiment with several Replicates of 2 or more Conditions (incl. one control, aka reference):\cr
 - In a paired (= "nested") setup, you would set refGroups to "ExpRep" and ratGroups to "Exp"\cr
 - In an unpaired setup, you would set both refGroups and ratGroups to "Exp"\cr
 Essentially, refGroups are the groups within which ratios are calculated to all available references in the group,\cr
 while ratGroups are comparison groups, i.e. several sample groups to compare to one another.)\cr
\cr}
}
\value{
A list:
 - "Data": output quantitative data.
 - "EList_obj": EList object, only present if LFQ_algo or reScaling = "limpa"
 - "QFeatures_obj": QFeatures object, only present if LFQ_algo or reScaling  = "QFeatures"
}
\description{
A function to calculate estimated protein group Expression (inter-protein group quantitation vectors) and Ratios (optional, intra-protein group fold changes) from individual peptide values.
The input is assumed to already be normalized!\cr
}
\examples{
temp <- protQuant(Prot = PG, pg_PepIDs = Pep4Quant, Pep = pep, pep_IDs = "New Peptide ID",
                  expMap = Exp.map,
                  refGroups = Ratios.Ref.Groups,
                  pepInt_Root = pep.ref, pepRat_root = pep.ratios.ref,
                  pepInt_log = FALSE, pepRat_log = 2,
                  protLFQ_toLog = TRUE, protRat_toLog = TRUE,
                  mods_to_Exclude = Mod2Xclud, mod_Seq = "Modified sequence",
                  minN = 2)

}
