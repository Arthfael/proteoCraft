############################################
#                                          #
# Histones tail modified peptides analysis #
#                                          #
############################################
#
# Can deal with DiaNN, FragPipe, Skyline or alphaDIA input.

wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(wd)
if (!require(pak)) {
  install.packages("pak")
  library(pak)
}
pkgs <- c("rstudioapi", "qs2", "plyr", "data.table", "openxlsx2", "svDialogs", "parallel", "limma", "plotly", "ggplot2", "viridis", "proteoCraft")
tst <- sapply(pkgs, function(pkg) { require(pkg, character.only = TRUE) })
if (sum(!tst)) {
  pak::pkg_install(pkgs[which(!tst)])
  for (pkg in pkgs[which(!tst)]) {
    library(pkg, character.only = TRUE)
  }
}
homePath <- paste0(normalizePath(Sys.getenv("HOME"), winslash = "/"), "/R/proteoCraft")

#proteoCraft::load_Bckp()

# For now I always need that one,
# but this could be easily modified
dbFl <- "D:/Fasta_databases/Mus_musculus/Mus_musculus_(C57BL-6J)_UP_20230201_Iso_noDupl_cont.fasta"

#updateMe <- c(TRUE, FALSE)[match(dlg_message("Update the proteoCraft package?", "yesno")$res, c("yes", "no"))]
updateMe <- FALSE
if (updateMe) {
  try({
    unloadNamespace("proteoCraft")
    remove.packages("proteoCraft")
  }, silent = TRUE)
  pak::pkg_install("Arthfael/proteoCraft")
}

# saveFun2 <- function(x, file) {
#   tmp <- paste0("qs::qsavem(", deparse(substitute(x)),
#                 ", file = '", file, "', nthreads = max(c(parallel::detectCores()-1, 1)))")
#   #cat(tmp)
#   eval(parse(text = tmp))
# }
# saveImgFun <- function(file) { # More elegant rewriting - I think
#   args2 <- list(file = file)
#   obj <- objects(.GlobalEnv)
#   obj <- setNames(lapply(obj, get, envir = .GlobalEnv), obj)
#   args2$x <- obj
#   do.call(qs::qsave, args2)
# }
# loadFun <- function(file) {
#   qs::qload(file, env = globalenv(), nthreads = max(c(parallel::detectCores()-1, 1)))
# }
RPath <- as.data.frame(library()$results)
RPath <- normalizePath(RPath$LibPath[match("proteoCraft", RPath$Package)], winslash = "/")
libPath <- paste0(RPath, "/proteoCraft")
homePath <- paste0(normalizePath(Sys.getenv("HOME"), winslash = "/"), "/R/proteoCraft")

# Set Shiny options, load functions for creating a Word report, create Excel styles
Src <- paste0(libPath, "/extdata/R scripts/Sources/ShinyOpt_Styles_and_Report.R")
#rstudioapi::documentOpen(Src)
source(Src, local = FALSE)

# Create parallel processing cluster
parSrc <- paste0(libPath, "/extdata/R scripts/Sources/make_check_Cluster.R")
#rstudioapi::documentOpen(Src)
source(parSrc, local = FALSE)

# Mode
inputTypes <- c("DiaNN", "FragPipe", "Skyline", "alphaDIA")
opt <- sapply(inputTypes, function(x) { paste(c(x, rep(" ", 250 - nchar(x))), collapse = "") })
inputType <- gsub(" +$", "", dlg_list(opt, opt[1], title = "Select type of input (NB: if wanting to combine the output of multiple folders, first run the corresponding combination script)")$res)

if ((exists("inDir"))&&(!is.null(inDir))&&(dir.exists(inDir))) { dfltDir <- inDir } else {
  if ((exists("parDir"))&&(!is.null(parDir))&&(dir.exists(parDir))) { dfltDir <- parDir } else {
    fl <- paste0(homePath, "/Default_locations.xlsx")
    if (file.exists(fl)) {
      tmp <- openxlsx2::read_xlsx(fl)
      dfltDir <- tmp$Path[match("Search folder", tmp$Folder)]
    } else {
      dfltDir <- "D:/groups_temp"
    }
  }
}
if (inputType == "FragPipe") {
  msg <- "Select folder in which FragPipe search result folder(s) are located"
  dflt <- inDir <- rstudioapi::selectDirectory(msg, path = dfltDir)
  parDir <- dirname(inDir)
}
if (inputType == "DiaNN") {
  msg <- "Select DiaNN log file"
  #filt <- matrix(c("DiaNN log file", "*.log.txt"), ncol = 2)
  #diaNN_log_fl <- normalizePath(choose.files(paste0(dfltDir, "/*.log.txt"), msg, multi = FALSE, filt, 1), winslash = "/")
  diaNN_log_fl <- rstudioapi::selectFile(msg,
                                         path = paste0(dfltDir, "/*.log.txt"),
                                         filter = "DiaNN log file (*.log.txt)")
  dflt <- inDir <- dirname(diaNN_log_fl)
  parDir <- dirname(inDir)
}
if (inputType == "Skyline") {
  msg <- "Select Skyline export .tsv file"
  #filt <- matrix(c("Skyline .tsv file", "Skyline .csv file", "*.tsv", "*.csv"), ncol = 2)
  #skyline_fl <- normalizePath(choose.files(paste0(dfltDir, "/*.tsv"), msg, multi = FALSE, filt, 1), winslash = "/")
  skyline_fl <- rstudioapi::selectFile(msg,
                                       path = paste0(dfltDir, "/*.tsv"),
                                       filter = "tsv file exported from Skyline (*.tsv)")
  dflt <- inDir <- dirname(skyline_fl)
  parDir <- dirname(inDir)
}
if (inputType == "alphaDIA") {
  msg <- "Select alphaDIA precursors .tsv file"
  #filt <- matrix(c("alphaDIA .tsv precursors file", "alphaDIA .parquet precursors file", "*.tsv", "*.parquet"), ncol = 2)
  #alphaDIA_fl <- normalizePath(choose.files(paste0(dfltDir, "/*.tsv"), msg, multi = FALSE, filt, 1), winslash = "/")
  alphaDIA_fl <- rstudioapi::selectFile(msg,
                                        path = paste0(dfltDir, "/*.tsv"),
                                        filter = "alphaDIA output tsv file (*.tsv)")
  dflt <- inDir <- dirname(alphaDIA_fl)
  parDir <- dirname(inDir)
}
dstDir <- rstudioapi::selectDirectory("Select output directory", path = dflt)
backupFl <- paste0(dstDir, "/Backup.RData")
write(inDir, paste0(dstDir, "/Input search directory.txt")) # In case I reprocess and do not have the backup file
#saveImgFun(backupFl)
#loadFun(backupFl)
if (inputType == "FragPipe") {
  fls <- list.files(inDir, full.names = TRUE, recursive = FALSE)
  FP_WorkflowFl <- grep("/fragpipe\\.workflow$", fls, value = TRUE)
  FP_ManifestFl <- grep("/fragpipe-files\\.fp-manifest$", fls, value = TRUE)
  stopifnot(length(FP_WorkflowFl) > 0, length(FP_ManifestFl) > 0)
  if (length(FP_WorkflowFl) > 1) {
    msg <- "Select FragPipe workflow files in the folder"
    opt <- setNames(sapply(FP_WorkflowFl, function(x) { paste(c(x, rep(" ", 250 - nchar(x))), collapse = "") }),
                    FP_WorkflowFl)
    FP_WorkflowFl <- gsub(" +$", "", dlg_list(opt, opt[1], title = msg)$res)
  }
  if (length(FP_ManifestFl) > 1) {
    msg <- "Select FragPipe manifest files in the folder"
    opt <- setNames(sapply(FP_ManifestFl, function(x) { paste(c(x, rep(" ", 250 - nchar(x))), collapse = "") }),
                    FP_ManifestFl)
    FP_ManifestFl <- gsub(" +$", "", dlg_list(opt, opt[1], title = msg)$res)
  }
  FP2MQ <- FP_to_MQ(FP_WorkflowFl, FP_ManifestFl, cl = parClust)
  ev <- FP2MQ$Evidence
  ev$`Raw file name` <- ev$`Raw file`
  #
  rawFiles <- unique(ev$"Raw file path")
  rawFiles2 <- unique(ev$`Raw file`)
  dbFl <- gsub("\\\\", "", gsub("\\\\\\\\", "/", gsub("^database.db-path=", "", grep("^database.db-path=", FP2MQ$WorkFlow, value = TRUE))))
  #
  ev$Bruker_runID <- as.integer(gsub(".*_|\\.d$", "", ev$`Raw file name`))
  ev$Scan_ID <- do.call(paste, c(ev[, c("Bruker_runID", "MS/MS scan number")], sep = "___"))
  ev$tmp <- round(ev$"m/z", 3)
  ev$Scan_ID_MZ <- do.call(paste, c(ev[, c("Scan_ID", "tmp")], sep = "___"))
  ev$tmp <- NULL
  Exp <- unique(ev$Experiment)
  Modifs <- FP2MQ$PTMs
  FracMap <- FP2MQ$FracMap
}
if (inputType == "DiaNN") {
  diaNN_log <- readLines(diaNN_log_fl)
  diaNN_Call <- grep("diann.exe ", diaNN_log, ignore.case = TRUE, value = TRUE)[1]
  if (is.na(diaNN_Call)) {
    diaNN_Call <- diaNN_log[grep("^Logical CPU cores:", diaNN_log)+1]
  }
  tmpCall <- unlist(strsplit(diaNN_Call, " +--"))
  PSMsFl <- gsub("\\\\", "/", gsub("^out +", "", grep("^out ", tmpCall, value = TRUE)))
  if (!file.exists(PSMsFl)) {
    PSMsFl2 <- paste0(dirname(diaNN_log_fl), gsub(".*/", "/", PSMsFl))
    if (file.exists(PSMsFl2)) {
      warning("The input folder has been renamed since DiaNN was run, but the report file could be located automatically.")
      PSMsFl <- PSMsFl2
    } else {
      warning("The input folder has been renamed since DiaNN was run, and the report file could not be located automatically; prompting user...")
      msg <- "Select DiaNN report file"
      xt <- gsub(".*\\.", "", PSMsFl)
      #PSMsFl <- choose.files(paste0(inDir, "/*.", xt), msg, FALSE)
      PSMsFl <- rstudioapi::selectFile(msg,
                                       path = paste0(inDir, "/*.", xt),
                                       filter = paste0("DiaNN ", xt, " report file (*.", xt, ")"))
    }
  }
  #
  PSMsFl <- normalizePath(PSMsFl, winslash = "/")
  #
  DiaNN2MQ <- try(DIANN_to_MQ(PSMsFl, cl = parClust), silent = TRUE)
  if ("try-error" %in% class(DiaNN2MQ)) { stop("Something went wrong!") }
  #
  Exp <- unique(DiaNN2MQ$Evidence$Experiment)
  if (!length(Exp)) {
    Exp <- unique(DiaNN2MQ$Evidence$"Raw file")
    DiaNN2MQ$Evidence$Experiment <- DiaNN2MQ$Evidence$"Raw file"
  }
  dbFl <- gsub("\\\\", "/", gsub("^fasta ", "", grep("^fasta ", tmpCall, value = TRUE)))
  if (!length(dbFl)) { # In the case of DiaNN, sometimes there is no fasta, only a library!
    dflt <- paste0(inDir, "/*.fasta")
    #msg <- "Select fasta file(s) used to create the library, or a compatible fasta file"
    #filt <- matrix(data = c("fasta", "*.fasta;*.fas;*.fa;*.fasta.fas"), ncol = 2, dimnames = list("Fasta"))
    #dbFl <- normalizePath(choose.files(dflt, filters = filt), winslash = "/")
    msg <- "Select fasta file used to create the library, or a compatible fasta file"
    dbFl <- rstudioapi::selectFile(msg,
                                   path = dflt,
                                   filter = "fasta file (*.fasta|*.fas|*.fa|*.faa|*.fasta.fas|*.txt)")
  }
  DiaNN2MQ$Exp <- Exp
  DiaNN2MQ$dbFl <- dbFl
  ev <- DiaNN2MQ$Evidence
  Modifs <- DiaNN2MQ$PTMs
  ev$"Raw file path" <- gsub("\\\\", "/", ev$"Raw file path")
  rawFiles <- unique(ev$"Raw file path")
  # nuFiles <- rawFiles <- unique(ev$"Raw file path")
  # wN <- which(!file.exists(nuFiles))
  # tmpDr <- inDir
  # while ((length(wN))&&(grepl("/", tmpDr))) {
  #   tmpFls <- paste0(tmpDr, gsub(".*/", "/", nuFiles[wN]))
  #   wY <- which(file.exists(tmpFls))
  #   nuFiles[wN][wY] <- tmpFls[wY]
  #   wN <- which(!file.exists(nuFiles))
  #   tmpDr <- gsub("/[^/]+$", "", tmpDr)  
  # }
  rawFilesExt <- gsub(".*\\.", "", rawFiles)
  wNtFnd <- which(!file.exists(rawFiles))
  updtFls <- FALSE
  if (length(wNtFnd)) {
    msg <- paste0(c("Some", "All")[(length(wNtFnd) == length(rawFiles))+1], " MS files are missing at the expected location.\n")
    tbl <- data.frame(path = rawFiles[wNtFnd], file = gsub(".*/", "", rawFiles[wNtFnd]), ext = rawFilesExt[wNtFnd])
    locs <- openxlsx::read.xlsx(paste0(homePath, "/Default_locations.xlsx"))
    dirs <- unique(unlist(lapply(unique(c(inDir, dirname(diaNN_log_fl))), function(dir) {
      dir <- c(dir, dirname(dir))
      return(c(dir,
               gsub(".*/", paste0(locs$Path[match("Archive folder", locs$Folder)], "/"), dir[1]),
               gsub(".*/", paste0(locs$Path[match("Archive folder", locs$Folder)], "/"), dir[2])))
    })))
    dirs <- dirs[which(dir.exists(dirs))]
    dirs <- dirs[which(dirs != ".")]
    dirFls <- setNames(lapply(dirs, function(dir) { list.files(dir, recursive = TRUE, full.names = TRUE) }), dirs)
    dirDFls <- setNames(lapply(dirs, function(dir) { grep("\\.d$", list.dirs(dir, recursive = TRUE, full.names = TRUE), value = TRUE) }), dirs)
    dirFls2 <- setNames(lapply(names(dirFls), function(nm) { basename(dirFls[[nm]]) }), dirs)
    dirDFls2 <- setNames(lapply(names(dirDFls), function(nm) { gsub(".*/", "", dirDFls[[nm]]) }), dirs)
    for (dir in dirs) {
      tbl[[dir]] <- apply(tbl[, c("file", "ext")], 1, function(x) { #x <- tbl[1, c("file", "ext")]
        rs <- NA
        if (x[[2]] == "d") {
          m <- match(x[[1]], dirDFls2[[dir]])
          if (!is.na(m)) { rs <- dirDFls[[dir]][m] }
        } else {
          m <- match(x[[1]], dirFls2[[dir]])
          if (!is.na(m)) { rs <- dirFls[[dir]][m] }
        }
        return(rs)
      })
    }
    tbl$nuLoc <- apply(tbl[, dirs, drop = FALSE], 1, function(x) {
      x <- x[which(!is.na(x))]
      if (!length(x)) { x <- NA }
      return(x)
    })
    wY <- which(!is.na(tbl$nuLoc))
    wN <- which(is.na(tbl$nuLoc))
    lY <- length(wY)
    lN <- length(wN)
    tstY1 <- (lY > 0)+1 # Did we manage to locate some files automatically?
    tstY2 <- (lY > 1)+1 # ... more than 1?
    tstN1 <- (lN > 0)+1 # Did we fail to for some?
    tstN2 <- (lN > 1)+1 # ... more than 1?
    if (tstY1 == 2) {
      updtFls <- TRUE
      msg <- paste0(msg, "However, the script automatically detected ",
                    c(c("the", "all")[tstY2], "the following")[tstN1], " file", c("", "s")[tstY2],
                    " at the following location", c("", "s")[tstY2], ":\n",
                    paste(paste0(" - ", tbl$nuLoc[wY], "\n"), collapse = ""))
      nuRawFiles <- rawFiles
      nuRawFiles[wNtFnd[wY]] <- tbl$nuLoc[wY]
      cat(msg)
    }
    cat(msg)
    if (tstN1 == 2) {
      msg2 <- paste0("Select the location of the missing file(s) (or cancel if files are unavailable):")
      newDir <- selectDirectory(msg2, path = wd)
      if (!is.null(newDir)) {
        newFls <- list.files(newDir, full.names = TRUE, include.dirs = TRUE, recursive = TRUE)
        newFlsTst <- gsub(".*/", "", newFls)
        wNA <- which(is.na(tbl$nuLoc))
        tst <- sapply(tbl$file[wNA], function(x) {
          x <- newFls[which(newFlsTst == x)]
          if (length(x) > 1) {
            nc <- nchar(x)
            x <- x[which(nc == min(nc))]
          }
          x
        })
        tst <- tst[which(sapply(tst, length) == 1)]
        tst <- setNames(unlist(tst), names(tst))
        wY2 <- which(is.na(tbl$nuLoc)&(tbl$file %in% names(tst)))
        wN2 <- which(is.na(tbl$nuLoc)&(!tbl$file %in% names(tst)))
        tstY2 <- (length(wY2) > 1)+1
        tstN2 <- (length(wN2) > 1)+1
        if (length(wY2)) {
          m <- match(tbl$file[wY2], names(tst))
          tbl$nuLoc[wY2] <- tst[m]
          msg <- "The user was able to locate the "
          if (length(wN2) == 0) {
            msg <- paste0(msg, "missing file", c("", "s")[tstY2],
                          " in directory ", newDir, "\n\n")
          } else {
            msg <- paste0(msg, "following missing file", c("", "s")[tstY2],
                          " in directory ", newDir, ":\n", paste0(" - ", tbl$file[wY2], collapse = "\n"), "\n\n")
          }
          cat(msg)
        } else {
          msg <- paste0("The following file", c("", "s")[tstN2], " could not be located:\n",
                        paste(paste0(" - ", tbl$path[wN], "\n\n"), collapse = ""))
        }
        nuRawFiles <- rawFiles
        w <- which(!is.na(tbl$nuLoc))
        updtFls <- length(w) > 0
        nuRawFiles[w] <- tbl$nuLoc[w]
      }
    }
  }
  rawFiles2 <- unique(ev$`Raw file`)
  FracMap <- data.frame("Raw file" = rawFiles,
                        "Raw files name" = rawFiles2,
                        "Parent sample" = rawFiles2,
                        "Fraction" = 1,
                        "Use" = TRUE,
                        check.names = FALSE)
}
if (inputType %in% c("alphaDIA", "Skyline")) {
  if (inputType == "alphaDIA") {
    #evTmp <- data.table::fread(alphaDIA_fl, integer64 = "numeric", check.names = FALSE, data.table = FALSE)
    alpha2MQ <- proteoCraft::alphaDIA_to_MQ(alphaDIA_fl, cl = parClust)
    #alpha2MQ <- alphaDIA_to_MQ(alphaDIA_fl, cl = parClust)
    ev <- alpha2MQ$Evidence
    Modifs <- alpha2MQ$PTMs
  }
  if (inputType == "Skyline") {
    #evTmp <- data.table::fread(skyline_fl, integer64 = "numeric", check.names = FALSE, data.table = FALSE)
    Sky2MQ <- proteoCraft::Skyline_to_MQ(skyline_fl, cl = parClust)
    #Sky2MQ <- Skyline_to_MQ(skyline_fl, cl = parClust)
    ev <- Sky2MQ$Evidence
    Modifs <- Sky2MQ$PTMs
  }
  if ("Raw file path" %in% colnames(ev)) {
    rawFiles <- unique(ev$"Raw file path")
    rawFiles2 <- gsub("\\.[^\\.]+$", "", gsub(".*/", "", rawFiles))
  } else {
    rawFiles2 <- rawFiles <- unique(ev$"Raw file")
    ev$"Raw file path" <- ev$"Raw file"
  }
  if (!"Experiment" %in% colnames(ev)) {
    ev$Experiment <- ev$"Raw file path"
  }
  FracMap <- data.frame("Raw file" = rawFiles,
                        "Raw files name" = rawFiles2,
                        "Parent sample" = rawFiles2,
                        "Fraction" = 1,
                        "Use" = TRUE,
                        check.names = FALSE)
}

# Remove reverse database hits
if ("Reverse" %in% colnames(ev)) {
  ev <- ev[which((is.na(ev$Reverse))|(ev$Reverse != "+")),]
}

# Fasta database and annotations 
w <- which(!file.exists(dbFl))
if (length(w)) {
  # Locate files!!!
  for (i in w) { #i <- w[1]
    tmp <- selectFile(paste0("Select missing fasta ", dbFl[i]), path = inDir)
    dbFl[i] <- gsub("^~", normalizePath(Sys.getenv("HOME"), winslash = "/"), tmp)
  }
}
if ((!exists("annot_Fl"))||(!file.exists(annot_Fl))||(gsub(".*\\.", "", annot_Fl) != "txt")) {
  annot_Fl <- gsub("\\.fas.*$", ".txt", dbFl)
}
tst <- file.exists(annot_Fl)
while (!tst) {
  annot_Fl <- selectFile("Select UniProtKB annotation txt file...", path = dirname(dbFl))
  tst <- file.exists(annot_Fl)
}
prsDB_Fl <- paste0(dstDir, "/Parsed DB.csv")
if (!file.exists(prsDB_Fl)) {
  dbs <- lapply(dbFl, function(x) { Format.DB(x, cl = parClust) })
  db <- plyr::rbind.fill(dbs)
  data.table::fwrite(db, prsDB_Fl, sep = ",", row.names = FALSE, na = "NA")
} else {
  db <- data.table::fread(prsDB_Fl, integer64 = "numeric", check.names = FALSE, data.table = FALSE) 
}
db <- db[grep("^>rev_", db$Header, invert = TRUE),] # Remove reverse database entries
parsedAnnot_Fl <- paste0(dstDir, "/Parsed Annot.rds")
if (!file.exists(parsedAnnot_Fl)) {
  annot <- Format.DB_txt(annot_Fl, Features = TRUE, cl = parClust)
  saveRDS(annot, parsedAnnot_Fl)
} else {
  annot <- readRDS(parsedAnnot_Fl)
}

# Check peptide-to-protein assignment, and isolate histones peptides
### NB: This doesn't take into consideration N-terminal methionines!!!
msg <- paste0("Update ", inputType, "'s original protein-to-peptides assignments?")
Update_Prot_matches <- c(TRUE, FALSE)[match(dlg_message(msg, "yesno")$res, c("yes", "no"))]
if (Update_Prot_matches) {
  fl <- paste0(dstDir, "/evmatch.RData")
  if (file.exists(fl)) { loadFun(fl) } else {
    Seq <- unique(ev$Sequence)
    DB <- db
    Src <- paste0(libPath, "/extdata/R scripts/Sources/ProtMatch2.R")
    #rstudioapi::documentOpen(Src)
    source(Src, local = FALSE)
    saveFun(evmatch, fl)
  }
  ev$Search_engine_proteins <- ev$Proteins
  ev$Proteins <- evmatch$Proteins[match(ev$Sequence, evmatch$Sequence)]
  #ev$Proteins <- ev$Search_engine_proteins
  #View(ev[, c("Search_engine_proteins", "Proteins", "Histone(s)", "Modified sequence_verbose")])
  #sum(ev$Search_engine_proteins != ev$Proteins)
  #sum(ev$Search_engine_proteins == ev$Proteins)
}
w <- which((ev$Proteins == "")|(is.na(ev$Proteins)))
lw <- length(w)
if (lw) {
  warning(paste0("Removing ", lw, " PSMs with no match to the database (", round(100*lw/nrow(ev), 1), "%)."))
  ev <- ev[which((ev$Proteins != "")&(!is.na(ev$Proteins))),]
}

#
# The part below is commented as it doesn't work!!!
# The idea was to ensure consistency when combining different searches...
# But when analyzing a single search, it was still removing PSMs!
# The reason: one MS2 can of course yield several PSMs, with close or even identical m/z...
# and all can be valid!!!
# One would need to also check which peaks were matched:
# - get all sequences and all MS2 spectra involved
# - calculate new scores
# - take the best match
# This would be very work intensive to write so has been dropped for now.
#
# When combining different searches, we want to make sure the same spectrum is not assigned
# different peptidoforms.
# Note: this can only work in DDA mode!
# tmp <- as.data.table(ev[, c("Scan_ID_MZ", "Modified sequence_verbose")])
# tmp <- tmp[, list(ModSeq = list(`Modified sequence_verbose`)), by = list(Scan_ID_MZ = Scan_ID_MZ)]
# tmp <- as.data.frame(tmp)
# tmp$L <- sapply(tmp$ModSeq, length)
# mx <- max(tmp$L)
# if (mx > 1) {
#   tstAmbig <- aggregate(tmp$L, list(tmp$L), length)
#   colnames(tstAmbig) <- c("Matches reported per m/z", "Scans")
#   View(tstAmbig)
#   Ambig <- tmp[which(tmp$L > 1),]
#   wAmbig <- which(ev$Scan_ID_MZ %in% Ambig$Scan_ID_MZ)
#   wClear <- which(!ev$Scan_ID_MZ %in% Ambig$Scan_ID_MZ)
#   kol <- c("Scan_ID", "Modified sequence_verbose", "Theoretical m/z", "m/z", "Score", "PEP")
#   stopifnot(sum(!kol %in% colnames(ev)) == 0)
#   tmp2 <- as.data.table(ev[wAmbig, kol])
#   tmp2 <- tmp2[, list(Score = list(Score),
#                       PEP = list(PEP),
#                       `m/z` = list(`m/z`),
#                       `theor m/z` = list(`Theoretical m/z`),
#                       ModSeq = list(`Modified sequence_verbose`)), by = list(Scan_ID = Scan_ID)]
#   tmp2 <- as.data.frame(tmp2)
#   tmp2$BestModSeq <- sapply(1:nrow(tmp2), function(x) {
#     Sc <- unlist(tmp2$Score[x])
#     mdSq <- unlist(tmp2$ModSeq[x])
#     PEP <- unlist(tmp2$PEP[x])
#     delta <- unlist(tmp2$`m/z`[x])-unlist(tmp2$`theor m/z`[x])
#     w <- which(Sc == max(Sc))
#     if (length(w) > 1) {
#       w <- w[which(delta[w] == min(delta[w]))]
#       if (length(w) > 1) {
#         w <- w[which(PEP[w] == min(PEP[w]))]
#       }
#     }
#     mdSq[w]
#   })
#   #class(tmp2$BestModSeq)
#   wU <- which(sapply(tmp2$BestModSeq, length) == 1)
#   wNU <- which(sapply(tmp2$BestModSeq, length) > 1)
#   if (length(wU)) {
#     tmpA <- do.call(paste, c(ev[wAmbig, c("Scan_ID", "Modified sequence_verbose")], sep = "___"))
#     tmpB <- do.call(paste, c(tmp2[wU, c("Scan_ID", "BestModSeq")], sep = "___"))
#     w <- which(tmpA %in% tmpB)
#     rmv <- nrow(ev)-length(c(wClear, w))
#     cat(paste0("Removing ", rmv, " PSMs in favour of a higher quality PSM to the same spectrum but from another search.\n"))
#     ev <- ev[c(wClear, w),]
#   }
#   if (length(wNU)) {
#     warning(paste0(length(wNU), " ambiguous spectra could not be resolved and were removed."))
#     ev <- ev[which(!ev$Scan_ID %in% tmp2$Scan_ID[wNU]),]
#   }
# }

mods <- Modifs
if (!"Delta" %in% colnames(mods)) {
  # Let's allow for my inconsistencies in naming the delta mass columns:
  if ("Mass delta" %in% colnames(mods)) { mods$Delta <- mods$"Mass delta" } else {
    if ("Mass shift" %in% colnames(mods)) { mods$Delta <- mods$"Mass shift" } else {
      if ("Delta mass" %in% colnames(mods)) { mods$Delta <- mods$"Delta mass" } else {
        if ("MW" %in% colnames(mods)) { mods$Delta <- mods$MW }
      }
    }
  }
}
mods <- mods[c(which(is.na(mods$`Old mark`)), which(!is.na(mods$`Old mark`))),]
mods$Delta <- as.numeric(mods$Delta)
mods <- mods[order(mods$Delta, decreasing = FALSE),]
kol <- colnames(mods)
kol <- kol[which(kol != "Old mark")]
modsTst <- do.call(paste, c(mods[, kol], sep = ""))
modsTst <- aggregate(1:nrow(mods), list(modsTst), min)
mods <- mods[modsTst$x,]
mods <- mods[c(which(is.na(mods$`Old mark`)), which(!is.na(mods$`Old mark`))),]
mods <- mods[order(mods$Delta, decreasing = FALSE),]
saveImgFun(backupFl)
#loadFun(backupFl)

# We now need to resolve cases where we got the PTM's name wrong
# - not that we made a mistake, but automation can only go so far.
# Here the issue is that FP takes as input just a delta mass, not a PTM,
# and to convert to MQ-like format we got a name from UniMod which may be incorrect.
# We also need to resolve ambiguous cases, where a single "mark" is assigned to 2 or more distinct PTMs.
# Let's do all of this at once.
msg <- paste0("Do you want to load an external table of PTMs names to force use of specific names?")
opt <- c("Yes                                                                                                                                                           ",
         "No                                                                                                                                                            ")
useExtTbl <- c(TRUE, FALSE)[match(dlg_list(opt, opt[2], title = msg)$res, opt)]
if (useExtTbl) {
  # This file is hard-coded in here: this is the table of mass-shift-to-PTM-name matches.
  # You can edit it but PLEASE stick to the current layout/logic or the script will BREAK!
  modTblFl <- rstudioapi::selectFile("histone_modification_masses.xlsx")
  stopifnot(file.exists(modTblFl))
  #
  useExtTbl <- dlg_message() 
  modTbl <- openxlsx2::read_xlsx(modTblFl)
  #openxlsx2::xl_open(modTblFl)
  colnames(modTbl)[1] <- "Priority"
  modTbl <- modTbl[which(!is.na(modTbl$"molecular weight")),]
  modTbl$`molecular weight` <- as.numeric(modTbl$`molecular weight`)
  modTbl$Priority[which(is.na(modTbl$Priority))] <- ""
  modTbl <- modTbl[which(modTbl$Priority != "Not analysed"),]
  tmp <- listMelt(strsplit(modTbl$`modified residues`, ","), 1:nrow(modTbl), c("Pos", "row"))
  tmp[, c("MW", "Name")] <- modTbl[tmp$row, c("molecular weight", "Modification")]
  tst <- aggregate(tmp$Name, list(tmp$Pos, tmp$MW), function(x) { length(unique(x)) })
  stopifnot(max(tst$x) == 1) # We assume that there is only one mod name for each combination of position and mass shift
  if (inputType %in% c("DiaNN", "Skyline")) {
    if ("Pos" %in% colnames(mods)) {
      mods$Site <- mods$Pos
    } else {
      if ("AA" %in% colnames(mods)) {
        mods$Site <- mods$A
      } else { stop() }
    }
    mods$"Mass delta" <- mods$Delta
  }
  mods2 <- listMelt(mods$Site, 1:nrow(mods), c("Pos", "row"))
  mods2[, c("MW", "Name", "Mark")] <- mods[mods2$row, c("Mass delta", "Full name", "Mark")]
  kol <- c("Pos", "MW")
  tmp$aggr <- do.call(paste, c(tmp[, kol], sep = "___"))
  mods2$aggr <- do.call(paste, c(mods2[, kol], sep = "___"))
  mods2$newName <- ""
  mods2$newMark <- mods2$Mark
  w <- which(mods2$aggr %in% tmp$aggr)
  mods2$newName[w] <- tmp$Name[match(mods2$aggr[w], tmp$aggr)]
  g1 <- grep("-", mods2$newName[w])
  g2 <- grep("-", mods2$newName[w], invert = TRUE)
  if (length(g1)) {
    mods2$newMark[w[g1]] <- sapply(strsplit(tolower(mods2$newName[w[g1]]), "-"), function(x) {
      paste0(substr(x[[1]], 1, 1), substr(x[[2]], 1, 1))
    })
  }
  if (length(g2)) {
    mods2$newMark[w[g2]] <- substr(tolower(mods2$newName[w[g2]]), 1, 2)
  }
  tst <- aggregate(mods2$MW, list(mods2$newMark), unique)
  wMult <- which(sapply(tst$x, length) > 1)
  if (length(wMult)) {
    mods2$newMark_tmp <- mods2$newMark
    for (i in wMult) {
      #i <- wMult[1]
      w <- which(mods2$newMark_tmp == tst$Group.1[i])
      m <- mods2[w,]
      m$Pos[which(sapply(m$Pos, length) == 0)] <- "X"
      r <- 1
      s <- 1:nrow(m); s <- s[which(s != r)]
      tst <- lapply(s, function(x) {
        paste0(tolower(m$Pos[[x]]), substr(m$newMark[[x]], 1, 1))
      })
      tst <- lapply(1:length(tst), function(x) {
        rs <- tst[[x]]
        rs[which(!rs %in% mods2$newMark)]
      })
      l <- length(tst)
      if (l > 1) {
        for (i in 2:l) {
          tst[[i]] <- tst[[i]][which(!tst[[i]] %in% unlist(tst[1:(i-1)]))]
        }
      }
      tst <- sapply(tst, function(x) {
        x <- unlist(x)
        if (length(x)) { x <- x[1] } else { x <- "That didnae work, did it?" }
        return(x)
      })
      tst2 <- ((tst %in% mods2$newMark)|(tst == "That didnae work, did it?"))
      w2 <- which(!tst2)
      m$newMark[s][w2] <- tst[w2]
      w1 <- which(tst2)
      if (length(w1)) {
        # not tested
        s1 <- s[w1]
        rs <- c()
        kount <- 1
        char <- c(0:9, letters)
        taken <- unique(c(mods2$newMark, m$newMark))
        for (j in s1) {
          tst <- paste0(tolower(m$Pos[s1]), char[kount])
          while (((tst) %in% taken)&&(kount < length(char))) {
            kount <- kount+1
            tst <- paste0(tolower(m$Pos[s1]), char[kount])
          }
          if (kount == length(char)) {
            stop("I am really out of options here, never thought this would go this far! Check the code just in case, this should never happen.")
          } else {
            rs <- c(rs, tst)
          }
        }
        m$newMark[[s1]] <- rs
      }
      mods2[w,] <- m
    }
  }
  tst <- aggregate(mods2$MW, list(mods2$newMark), unique)
  stopifnot(is.numeric(tst$x))
  mods <- mods2; rm(mods2)
  w <- which(mods$newName == "")
  mods$newName[w] <- mods$Name[w]
  mods$newName <- gsub("\\)", ">", gsub("\\(", "<", mods$newName))
  nmKol <- "Name"
  if (!"Modified sequence_verbose" %in% colnames(ev)) {
    ev$"Modified sequence_verbose" <- ev$`Modified sequence`
    nmKol <- "Mark"
  }
  unq <- grep("\\(", unique(ev$`Modified sequence_verbose`), value = TRUE)
  mods2 <- mods
  mods2$newMark <- paste0("(", mods2$newMark, ")")
  mods2$newName <- paste0("(", mods2$newName, ")")
  clusterExport(parClust, list("mods2", "nmKol"), envir = environment())
  unq2 <- as.data.frame(t(parSapply(parClust, unq, function(x) {
    #x <- unq[1]
    x <- y <- proteoCraft::annot_to_tabl(x)[[1]]
    w <- which(x$Annotations != "")
    m <- match(x$Annotations[w], mods2[[nmKol]])
    x$Annotations[w] <- mods2$newMark[m]
    y$Annotations[w] <- mods2$newName[m]
    x <- do.call(paste, c(x, sep = "", collapse = ""))
    y <- do.call(paste, c(y, sep = "", collapse = ""))
    return(c(x, y))
  })))
  tst1 <- gsub("\\)[A-Z]*\\(", "___", gsub("_[A-Z]+_|_[A-Z]*\\(|\\)[A-Z]*_", "", unq2[[1]]))
  tst2 <- gsub("\\)[A-Z]*\\(", "___", gsub("_[A-Z]+_|_[A-Z]*\\(|\\)[A-Z]*_", "", unq2[[2]]))
  tst1 <- unique(unlist(strsplit(tst1, "___")))
  tst2 <- unique(unlist(strsplit(tst2, "___")))
  stopifnot(sum(!tst1 %in% mods$newMark) == 0,
            sum(!tst2 %in% mods$newName) == 0)
  w <- which(ev$`Modified sequence_verbose` %in% unq)
  m <- match(ev$`Modified sequence_verbose`[w], unq)
  ev$`Modified sequence`[w] <- unq2[m, 1]
  ev$`Modified sequence_verbose`[w] <- unq2[m, 2]
  # Done!!!
  # Pfeewwwww...
}

# Edit samples map
smplsMapFl <- paste0(dstDir, "/Samples_map.csv")
ok <- FALSE
kount <- 0
while (!ok) {
  reLoad <- FALSE
  kol <- "Experiment"
  if (file.exists(smplsMapFl)) {
    tmp <- read.csv(smplsMapFl)
    kol <- c(kol, "Old_Experiment")[("Old_Experiment" %in% colnames(ev))+1]
    if ((sum(c("Old", "New", "Group", "Replicate") %in% colnames(tmp)) == 4)&&(sum(!unique(ev[[kol]]) %in% tmp$Old) == 0)) {
      msg <- paste0("Valid samples map template detected at:\n", smplsMapFl, ". Re-load it?")
      reLoad <- c(TRUE, FALSE)[match(dlg_message(msg, "yesno")$res, c("yes", "no"))]
    }
  }
  if (!reLoad) {
    tmp <- data.frame(Old = unique(ev[[kol]]),
                      New = unique(ev[[kol]]),
                      Group = "?",
                      Replicate = "?")
    tst <- try(write.csv(tmp, smplsMapFl, row.names = FALSE), silent = TRUE)
    if ("try-error" %in% class(tst)) {
      dlg_message(paste0("File \"", smplsMapFl, "\" appears to be locked for editing, close the file then click ok..."), "ok")
      write.csv(tmp, smplsMapFl, row.names = FALSE)
    }
  }
  cmd <- paste0("open \"", smplsMapFl, "\"")
  system(cmd)
  msg <- c("Make your edits in the table then click ok...\nAlso add any metadata column which contains information relevant to batch correction!\n",
           "The last version did not have the expected columns (\"Old\" and \"New\"),\nplease make your edits in the table then click ok...\n")[(kount > 0)+1]
  dlg_message(msg, "ok")
  smplsMap <- read.csv(smplsMapFl)
  ok <- sum(!c("Old", "New", "Group") %in% colnames(smplsMap)) == 0
  kount <- kount + 1
}
ev$Old_Experiment <- ev$Experiment
ev$Experiment <- smplsMap$New[match(ev$Old_Experiment, smplsMap$Old)]
u <- unique(ev$Experiment)
if ((length(u) == 1)&&(is.na(u))) {
  # For when rerunning in bits!
  ev$Experiment <- ev$Old_Experiment
  ev$Old_Experiment <- smplsMap$Old[match(ev$Experiment, smplsMap$New)]
}
Exp <- unique(ev$Experiment)

# Edit groups map
statTsts <- FALSE
grpsMapFl <- paste0(dstDir, "/Groups_map.csv")
ok <- FALSE
kount <- 0
Groups <- unique(smplsMap$Group)
while (!ok) {
  reLoad <- FALSE
  if (file.exists(grpsMapFl)) {
    tmp <- read.csv(grpsMapFl)
    if ((sum(c("Group", "Reference", "Comparison_group") %in% colnames(tmp)) == 3)&&(sum(!unique(smplsMap$Group) %in% tmp$Group) == 0)) {
      msg <- paste0("Valid Groups map template detected at:\n", grpsMapFl, ". Re-load it?")
      reLoad <- c(TRUE, FALSE)[match(dlg_message(msg, "yesno")$res, c("yes", "no"))]
    }
  }
  if (!reLoad) {
    tmp <- data.frame(Group = Groups,
                      Reference = FALSE,
                      Comparison_group = 1)
    write.csv(tmp, grpsMapFl, row.names = FALSE)
    cat(paste0("Groups map template created at:\n", grpsMapFl, "\n"))
  }
  cmd <- paste0("open \"", grpsMapFl, "\"")
  system(cmd)
  msg <- c("Make your edits in the Groups table then click ok",
           "The last version did not have the expected columns (\"Old\" and \"New\"),\n
             please make your edits in the table then click ok")[(kount > 0)+1]
  dlg_message("Make your edits in the table then click ok", "ok")
  grpsMap <- read.csv(grpsMapFl)
  ok <- (sum(!c("Group", "Reference", "Comparison_group") %in% colnames(grpsMap)) == 0)
  if (ok) {
    grpsMap$Reference <- as.logical(grpsMap$Reference)
    tst <- aggregate(grpsMap$Reference, list(grpsMap$Comparison_group), function(x) { sum(c(FALSE %in% x, TRUE %in% x, length(unique(x)) == 2)) })
    statTsts <- ((length(unique(tst$x)) == 1)&&(unique(tst$x) == 3))
    if (!statTsts) {
      warning("No statistical tests will be performed!")
    }
  }
  kount <- kount + 1
}
compGrps <- unique(grpsMap$Comparison_group)
smplsMap$Comparison_group <- grpsMap$Comparison_group[match(smplsMap$Group, grpsMap$Group)]
smplsMap$Reference <- grpsMap$Reference[match(smplsMap$Group, grpsMap$Group)]

isQuant <- ("Intensity" %in% colnames(ev))
if (!isQuant) {
  warning("No Intensity column detected, this is necessary for going further with this workflow...")
}

Nested <- FALSE
if (statTsts) {
  # Nested (paired) replicates?
  opt <- c("Yes                                                                                                                                                               ",
           "No                                                                                                                                                                ")
  Nested <- c(TRUE, FALSE)[match(dlg_list(opt, opt[2], title = "Are the replicates paired?")$res, opt)]
}

Remove0Int <- FALSE
#Remove0Int <- c(FALSE, TRUE)[match(dlg_message("Should we keep peptides with 0 intensity values?", "yesno")$res, c("yes", "no"))]
if (Remove0Int) { ev <- ev[which(ev$Intensity > 0),] }

histDir <- paste0(dstDir, "/Histones_coverage_maps")
if (!dir.exists(histDir)) { dir.create(histDir) } else {
  ls <- list.files(histDir, full.names = TRUE)
  if (length(ls)) {
    msg <- "The coverage maps folder is not empty, clear it?"
    clearDir <- c(TRUE, FALSE)[match(dlg_message(msg, "yesno")$res, c("yes", "no"))]
    if (clearDir) {
      for (fl in ls) { unlink(fl) }
    }
  }
}

# Histone IDs
Hist <- grep("histone", db$Header, ignore.case = TRUE, value = TRUE)
Hist <- grep("ase(,|\\.| )", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("-(binding|like)", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("chaperone", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("ethyl", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("factor", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("non-histone", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
Hist <- grep("\\(fragment\\)", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
coreHist <- grep("H1|H5|linker", Hist, ignore.case = TRUE, value = TRUE, invert = TRUE)
HistIDs <- db$`Protein ID`[match(Hist, db$Header)]
coreHistIDs <- db$`Protein ID`[match(coreHist, db$Header)]
histDB <- db[match(HistIDs, db$`Protein ID`),]
#unique(db$`Common Name`[match(Hist, db$Header)])
# Default organism may not be correct:
writeFasta(histDB, paste0(dstDir, "/M_musculus_all_histones.fasta"))
histDB$ID_Nm <- apply(histDB[, c("Protein ID", "Common Name")], 1, paste, collapse = " - ")
histDB$ID_Nm <- gsub("/", "_", histDB$ID_Nm)
clusterExport(parClust, "histDB", envir = environment())

###################################################################################
# Identify the boundary between each histone's ordered domain and disordered tail #
###################################################################################
#
# We will want to normalize to the relatively unmodified, histone-fold domains.
# That way we normalize to what we are interested in (histones) and not affected by tail-borne variable PTMs (what we want to test).
# Note: yes I know there are PTMs also on the structured part. We will either ignore them because they are less many/less variable,
# or we will remove them and their counterpart peptide when identified. TO BE DECIDED!!!
# The annotation tables from UniProtKB identify part of histone sequences as "Disordered": this is the tail, and will be how we identify them.
#
coreHistAnnot <- setNames(lapply(coreHistIDs, function(x) { annot[grsep(x, x = annot$Accession),] }), coreHistIDs)
coreHistAnnot <- coreHistAnnot[which(sapply(coreHistAnnot, nrow) > 0)]
#
#View(coreHistAnnot$Features[[1]])
Features <- lapply(names(coreHistAnnot), function(hist) { #hist <- names(coreHistAnnot)[1] #hist <- "G3UX40"
  x <- coreHistAnnot[[hist]]$Features[[1]]
  #View(x)
  rs <- list(Histone = hist,
             Sequence = histDB$Sequence[match(hist, histDB$`Protein ID`)])
  rs$Ordered <- list(rs$Sequence)
  if ("Note" %in% colnames(x)) {
    w <- which(sapply(x$Note, function(y) { "Disordered" %in% y }))
    lW <- length(w)
    if (lW) {
      sq <- unlist(strsplit(rs$Sequence, ""))
      rmv <- x[w, c("Start", "End"), drop = FALSE]
      rmv <- apply(rmv, 1, function(x) { x[[1]]:x[[2]] })
      rmv <- as.numeric(unlist(rmv))
      sq[rmv] <- "_"
      sq <- unlist(strsplit(gsub("^_+|_+$", "", paste(sq, collapse = "")), "_+"))
      rs$Ordered <- sq
    }
  }
  return(rs)
})
Ordered <- data.frame(Accession = names(coreHistAnnot),
                      Name = histDB$`Common Name`[match(names(coreHistAnnot), histDB$`Protein ID`)],
                      Sequence = histDB$Sequence[match(names(coreHistAnnot), histDB$`Protein ID`)])
Ordered$Ordered <- lapply(Features, function(x) { x$Ordered })
Ordered2 <- Ordered
Ordered2$Ordered <- sapply(Ordered2$Ordered, paste, collapse = " / ")
write.csv(Ordered2, file = paste0(dstDir, "/Ordered_histone_domains.csv"), row.names = FALSE)
###################################################################################
#                                 Et voila, done!                                 #
###################################################################################

if (useExtTbl) {
  tmp <- data.frame(ModSeq =  ev$"Modified sequence_verbose")
  tmp$tst <- gsub("^_[A-Z]+_$|^_[A-Z]*\\(|\\)[A-Z]*_$", "",
                  gsub("\\)[A-Z]+\\(", "___", tmp$ModSeq))
  tst <- unlist(strsplit(tmp$tst, "___"))
  tst <- aggregate(tst, list(tst), length)
  nrow(tst) # Number of identified PTMs
  length(unique(mods$newName)) # Number of searched PTMs
  stopifnot(sum(!tst$Group.1 %in% mods$newName) == 0) # Checking that the names match
}

tmp <- strsplit(ev$Proteins, ";")
tmp <- proteoCraft::listMelt(tmp, 1:nrow(ev), c("ID", "row"))
tmp <- tmp[which(tmp$ID %in% histDB$`Protein ID`),]
tmp <- data.table::as.data.table(tmp)
tmp <- tmp[, list(IDs = list(ID)), by = list(row = row)]
tmp <- as.data.frame(tmp)
tmp$IDs <- parSapply(parClust, tmp$IDs, paste, collapse = ";")
ev$"Histone(s)" <- ""
ev$"Histone(s)"[tmp$row] <- tmp$IDs
#View(ev[tmp$row, c("Proteins", "Histone(s)")])
sum(ev$Proteins != ev$`Histone(s)`)
sum(ev$Proteins == ev$`Histone(s)`)

tmp <- ev[, c("Histone(s)", "Proteins")]
tmp$"Proteins" <- strsplit(tmp$"Proteins", ";")
tmp$"Histone(s)" <- strsplit(tmp$"Histone(s)", ";")
tst <- apply(tmp[, c("Histone(s)", "Proteins")], 1, function(x) {
  sum(!x[[1]] %in% x[[2]])
})
w <- which(tst > 0)
#View(ev[w, c("Modified sequence_verbose", "Histone(s)", "Proteins")])
#View(ev[grep("phospho", ev$`Modified sequence_verbose`, ignore.case = TRUE), c("Modified sequence_verbose", "Histone(s)", "Proteins")])

invisible(parLapply(parClust, 1:N.clust, function(x) { rm(list = ls());gc() }))
saveImgFun(backupFl)
#loadFun(backupFl)

# Summarize over charge
if (!"Raw file path" %in% colnames(ev)) {
  stopifnot("Raw file" %in% colnames(ev))
  ev$"Raw file path" <- ev$`Raw file`
}
if (!"Potential contaminant" %in% colnames(ev)) { ev$"Potential contaminant" <- "" }
if (!"Reverse" %in% colnames(ev)) { ev$"Reverse" <- "" }
kol1 <- c("Modified sequence", "Raw file path", "Experiment")
kol2 <- c("Intensity", "Charge", "m/z", "Score")
#c(kol1, kol2)[which(!c(kol1, kol2) %in% colnames(ev))]
if (sum(!c(kol1, kol2) %in% colnames(ev))) {
  stop("Some columns necessary for going further with this workflow are missing...")
}
# We will allow summing if several raw files are assigned the same Experiment
evSum <- as.data.table(ev[, c(kol1, kol2)])
evSum <- evSum[,
               list(Intensity = sum(Intensity, na.rm = TRUE),
                    Charge = paste(Charge, collapse = ";"),
                    `m/z` = paste(`m/z`, collapse = ";"),
                    Score = max(Score, na.rm = TRUE)),
               by = list(`Modified sequence` = `Modified sequence`,
                         #`Raw file path` = `Raw file path`,
                         Experiment = Experiment)]
evSum <- as.data.frame(evSum)
kol3 <- c("Modified sequence_verbose", "Modifications", "Proteins", "Histone(s)", "Mass",
          "Missed cleavages", "Potential contaminant", "Reverse")
kol3 <- kol3[which(kol3 %in% colnames(ev))]
evSum[, kol3] <- ev[match(evSum[["Modified sequence"]], ev[["Modified sequence"]]), kol3]
kol4 <- c("Modified sequence", "Modified sequence_verbose", "Modifications", "Intensity",
          "Raw file path", "Experiment", "Proteins", "Histone(s)", "Mass", "Charge", "m/z", "Score",
          "Missed cleavages", "Potential contaminant", "Reverse")
kol4 <- kol4[which(kol4 %in% colnames(evSum))]
evSum <- evSum[, kol4]

Exp <- unique(evSum$Experiment)

PSMs_per_Histone <- aggregate(evSum$"Histone(s)", list(evSum$"Histone(s)"), length)
colnames(PSMs_per_Histone) <- c("Histone matches", "Peptides")
PSMs_per_Histone <- PSMs_per_Histone[which(PSMs_per_Histone$`Histone matches` != ""),]
PSMs_per_Histone <- PSMs_per_Histone[order(PSMs_per_Histone$Peptides, decreasing = TRUE),]
View(PSMs_per_Histone)

w <- which(parSapply(parClust, strsplit(evSum$`Histone(s)`, ";"), function(x) {
  x <- unlist(x)
  x <- x[which(x != "")]
  (length(x) > 1)||(!is.na(x))
}))
histEv <- evSum[w,]
tst <- gsub("^_[A-Z]+_$|^_[A-Z]*\\(|\\)[A-Z]*_$", "", gsub("\\)[A-Z]+\\(", "___",
                                                           histEv$`Modified sequence_verbose`))
tst <- unlist(strsplit(tst, "___"))
tst <- aggregate(tst, list(tst), length)
nrow(tst) # Number of identified PTMs
stopifnot(sum(!unique(unlist(strsplit(histEv$`Histone(s)`, ";"))) %in% histDB$`Protein ID`) == 0)
histEv$Sequence <- ev$Sequence[match(histEv$`Modified sequence`, ev$`Modified sequence`)]

# Check PTMs
wMod <- grep("\\(", histEv$`Modified sequence_verbose`)
tmpMds <- gsub("^_?[A-Z]+_?$|^_?[A-Z]*\\(|\\)[A-Z]*_?$", "",
               gsub("\\)[A-Z]*\\(", "___", unique(histEv$`Modified sequence_verbose`[wMod])))
ptmTst <- unlist(strsplit(tmpMds, "___"))
ptmTst <- aggregate(ptmTst, list(ptmTst), length)
colnames(ptmTst) <- c("PTM", "Nb. of Histone peptidoforms")
ptmTst <- ptmTst[order(ptmTst$`Nb. of Histone peptidoforms`, decreasing = TRUE),]
View(ptmTst)
data.table::fwrite(ptmTst, paste0(histDir, "/Histone PTMs summary.csv"), sep = ",", row.names = FALSE, na = "NA")

# Histones PTM sites count
kol <- c("Sequence", "Modified sequence_verbose", "Proteins")
tmp <- histEv[wMod, kol]
tst <- do.call(paste, c(tmp, sep = "___"))
tst <- unique(tst)
tmp <- Isapply(strsplit(tst, split = "___"), unlist)
colnames(tmp) <- kol
tmp2 <- unlist(strsplit(tmp$Proteins, ";"))
tmp2 <- aggregate(tmp2, list(tmp2), length)
tmp2 <- tmp2[order(tmp2$x, decreasing = TRUE),]
clusterExport(parClust, "tmp2", envir = environment())
tmp$Proteins_by_pep <- parSapply(parClust, strsplit(tmp$Proteins, ";"), function(x) { #x <- strsplit(tmp$Proteins[5], ";")
  x <- unlist(x)
  if (length(x) > 1) {
    o <- tmp2$x[match(x, tmp2$Group.1)]
    x <- x[order(o, decreasing = TRUE)]
    x <- paste(sort(unlist(x)), collapse = ";")
  }
  return(x)
})
tmp$First_Protein <- gsub(";.*", "", tmp$Proteins_by_pep)
tmpSq <- paste0("_", db$Sequence[match(tmp$First_Protein, db$`Protein ID`)])
tmp$Match <- sapply(1:nrow(tmp), function(x) {
  nchar(unlist(strsplit(tmpSq[x], tmp$Sequence[x]))[1])
})
tmp$Tbl <- lapply(tmp$`Modified sequence_verbose`, proteoCraft::annot_to_tabl)
tmp$Sites <- lapply(1:nrow(tmp), function(x) { #x <- 1
  mtch <- tmp$Match[x]
  pr <- tmp$First_Protein[x]
  tbl <- tmp$Tbl[[x]]
  tbl <- tbl[[1]]
  nr <- nrow(tbl)-2
  tbl$Dist <- c(1, 1:nr, nr)
  tbl$Pos <- tbl$Dist + mtch - 1
  tbl <- tbl[which(tbl$Annotations != ""), , drop = FALSE]
  tbl$Site <- apply(tbl[, c("Sequence", "Pos", "Annotations")], 1, function(y) {
    paste0(pr, " ", y[[1]], y[[2]], "(", y[[3]], ")")
  })
  return(tbl$Site)
})
Sites <- unique(unlist(tmp$Sites))
Sites <- data.frame(Site = Sites)
Sites$Type <- gsub(".*\\(|\\)", "", Sites$Site)
nSites <- aggregate(Sites$Type, list(Sites$Type), length)
nSites <- nSites[order(nSites$x, decreasing = TRUE),]
colnames(nSites) <- c("PTM", "Nb. of sites")
View(nSites)
data.table::fwrite(nSites, paste0(histDir, "/Histone PTM sites summary.csv"), sep = ",", row.names = FALSE, na = "NA")
sum(nSites$`Nb. of sites`[which(!nSites$PTM %in% c("Carbamidomethyl", "Oxidation"))])

saveImgFun(backupFl)
#loadFun(backupFl)

# Coverage maps
kol <- c("Experiment", "Histone(s)", "Intensity", "Modified sequence", "Modified sequence_verbose")
kol %in% colnames(histEv)
tmpEv <- histEv[, kol]
clusterExport(parClust, list("tmpEv", "histDir", "Hist", "Coverage", "histDB"), envir = environment())
#clusterExport(parClust, "Coverage", envir = environment())
for (e in Exp) { #e <- Exp[1]
  w <- which(tmpEv$Experiment == e)
  #w <- which(tmpEv$Experiment %in% Exp)
  if (length(w)) {
    pp <- tmpEv[w,]
    pp <- aggregate(pp$Intensity,
                    list(pp$`Modified sequence`, pp$`Modified sequence_verbose`),
                    sum, na.rm = TRUE)
    colnames(pp) <- c("Modified sequence", "Modified sequence_verbose", "Intensity")
    pp$"Histone(s)" <- tmpEv$"Histone(s)"[match(pp$`Modified sequence`, tmpEv$`Modified sequence`)]
    tmpPP <- listMelt(strsplit(pp$"Histone(s)", ";"), 1:nrow(pp), c("Histone", "row"))
    tmpPP <- aggregate(tmpPP$row, list(tmpPP$"Histone"), c)
    tmpPP <- setNames(lapply(tmpPP$x, function(x) {
      pp[x, c("Modified sequence_verbose", "Intensity")]
    }), tmpPP$Group.1)
    e <- gsub("[\\\\/:\\*\\?\"<>\\|]", "_", e)
    clusterExport(parClust, list("e", "tmpPP"), envir = environment())
    # tst <- sapply(names(tmpPP), function(x) {
    #   g <- grep("nyl", tmpPP[[x]]$`Modified sequence_verbose`, value = TRUE)
    #   if (length(g)) { stop(cat(x, "\n", paste(g, collapse = "\n"), "\n")) }
    # })
    # View(tmpPP[["A0A2R8Y619"]])
    w <- which(histDB$`Protein ID`[match(Hist, histDB$Header)] %in% names(tmpPP))
    if (length(w)) {
      a <- parSapply(parClust, Hist[w], function(hist) {
        #hist <- Hist[w][1]
        #hist <- grep("G3UX40", Hist[w], value = TRUE)
        #hist <- grep("G3UWL7", Hist[w], value = TRUE)
        #hist <- grep("A0A0N4SV66", Hist[w], value = TRUE)
        #hist <- grep("A0A8I4SYN6", Hist[w], value = TRUE)
        #for (hist in Hist[w]) {
        #grep("Q07133", Hist[w])
        m <- match(hist, histDB$Header)
        if (length(m)) {
          nm <- histDB$ID_Nm[m]
          sq <- setNames(histDB$Sequence[m], histDB$ID_Nm[m])
          tmpSq <- tmpPP[[histDB$`Protein ID`[m]]]
          Coverage(sq, tmpSq$`Modified sequence_verbose`, "Heat", FALSE, FALSE,
                   title = paste0(nm, " coverage - ", e),
                   intensities = tmpSq$Intensity,
                   save.path = paste0(histDir, "/", nm, " - ", e),
                   save = c("pdf", "jpeg"))
          fl <- paste0(histDir, "/", nm, " - ", e)
          if (file.exists(fl)) { unlink(fl) }
        } else { stop() }
      }) 
    }
  }
}

smpls <- unique(smplsMap$New)

#openwd(histDir)
data.table::fwrite(histEv, paste0(histDir, "/Hist_peptidoforms.tsv"),
                   sep = "\t", row.names = FALSE, na = "NA")
#openxlsx2::xl_open(paste0(histDir, "/Hist_peptidoforms.tsv"))

# Wide peptides table
kol <- colnames(evSum)
kol2 <- c("id", "Raw file", "Raw file2", "Raw file path", "Retention time (start)", "Retention time (end)", "Retention length", "Score", "q-value", "Charge", "Library index", "Library rt",
          "MS2 intensities", "MS/MS scan number", "IM", "IM (predicted)", "iIM", "iIM (predicted)", "Experiment", "Old_Experiment", "Search_engine_proteins", "Retention time",
          "Retention time (predicted)", "iRT", "iRT (predicted)", "Intensity", "PEP", "Theoretical m/z", "m/z", "Mass", "Delta score")
kol1 <- kol[which(!kol %in% kol2)]
tmp <- do.call(paste, c(evSum[, kol1], sep = "_<>_"))
tmp <- aggregate(1:nrow(evSum), list(tmp), min)
pep <- evSum[tmp$x, kol1]
#
# Quantitative values
intType <- "Original"
intRoot <- setNames("Intensity - ", intType)
logIntRoot <- setNames("log10(int.) - ", intType)
ratRoot <- "log2(Ratio) - "
#
tmp <- evSum[, c("Experiment", "Modified sequence", "Intensity")]
exports <- list("smpls", "smplsMap", "tmp", "intRoot", "is.all.good")
clusterExport(parClust, exports, envir = environment())
clusterCall(parClust, function() library(data.table))
tmp4 <- setNames(parLapply(parClust, smpls, function(smpl) { #smpl <- smpls[1]
  w <- which(tmp$Experiment == smpl)
  tmp2 <- data.frame(mod = NA, Intensity = NA)
  if (length(w)) {
    tmp2 <- data.table(mod = tmp[w, "Modified sequence"],
                       Intensity = tmp[w, "Intensity"])
    tmp2$Intensity[which(!is.all.good(tmp2$Intensity, 2))] <- NA
    tmp2$Intensity[which(tmp2$Intensity <= 0)] <- NA
    tmp2 <- tmp2[, list(Intensity = sum(Intensity, na.rm = TRUE)), by = list(mod)]
    tmp2 <- as.data.frame(tmp2)
  }
  return(tmp2)
}), smpls)
for (smpl in smpls) { #smpl <- smpls[1]
  tmp <- tmp4[[smpl]]
  pep[[paste0(intRoot[intType], smpl)]] <- NA
  w <- which(pep$"Modified sequence" %in% tmp$mod)
  pep[w, paste0(intRoot[intType], smpl)] <- tmp$Intensity[match(pep$"Modified sequence"[w], tmp$mod)]
}
pep$id <- 1:nrow(pep)
#
labCol <- c("ModSeq", "Proteins", "Name", "Gene names")
w <- which((labCol %in% colnames(ev))&(!labCol %in% colnames(evSum)))
if (length(w)) { evSum[, labCol[w]] <- ev[match(evSum$`Modified sequence`, ev$`Modified sequence`), labCol[w]] }
w <- which((labCol %in% colnames(evSum))&(!labCol %in% colnames(pep)))
if (length(w)) { pep[, labCol[w]] <- evSum[match(pep$`Modified sequence`, evSum$`Modified sequence`), labCol[w]] }
pep$ModSeq <- gsub("^_|_$", "", pep$`Modified sequence`)
pep$Name <- db$`Common Name`[match(gsub(";.*", "", pep$Proteins), db$`Protein ID`)]
w <- which(is.na(pep$Name))
pep$Name[w] <- "No match!"
labCol <- labCol[which(labCol %in% colnames(pep))]
clusterExport(parClust, "labCol", envir = environment())
pep$Label <- parApply(parClust, pep[, labCol, drop = FALSE], 1, function(x) {
  paste0(labCol, ": ", x, collapse = "\n")
})
pep$Sequence <- ev$Sequence[match(pep$`Modified sequence_verbose`, ev$`Modified sequence_verbose`)]
intType <- "Original"
normSummary <- data.frame(Sample = smpls, Original = sapply(smpls, function(x) { median(pep[[paste0(intRoot[intType], x)]], na.rm = TRUE) }))

#
saveImgFun(backupFl)

# Batch correction:
kol <- colnames(smplsMap)
kol <- kol[which(!kol %in% c("Old", "New", "Group", "Comparison_group",  "Reference"))]
kol <- kol[which(sapply(kol, function(k) {
  length(unique(smplsMap[[k]])) > 1
}))]
if (length(kol)) {
  dflt <- kol
  if (!Nested) {
    dflt <- dflt[which(dflt != "Replicate")]
  }
  if (exists("myBatches")) {
    dflt <- myBatches
  }
  kol <- setNames(sapply(kol, function(k) { paste(c(k, rep(" ", max(c(200, nchar(k))))), collapse = "") }), kol)
  dflt <- setNames(kol[match(dflt, names(kol))], dflt)
  myBatches <- dlg_list(kol, dflt,
                        title = "Select any known batch variables to explore sequentially correcting against",
                        multiple = TRUE)$res
  myBatches <- names(kol)[match(myBatches, kol)]
  combatNorm <- length(myBatches)
  if (combatNorm) {
    #
    # Check for synonymous batches
    tmp <- smplsMap[, myBatches]
    for (btch in myBatches) {
      tmp[[btch]] <- as.numeric(as.factor(tmp[[btch]]))
    }
    comb <- gtools::combinations(length(myBatches), 2, myBatches)
    comb <- as.data.frame(comb)
    tst <- apply(comb, 1, function(x) {
      identical(tmp[[x[1]]], tmp[[x[2]]])
    })
    w <- which(tst)
    if (length(w)) {
      btchs2Remove <- unique(comb[w, 2])
      warning(paste0("The following batches are synonymous: ",
                     paste(do.call(paste, c(comb[w,], sep = " and ")), collapse = ", "),
                     ".\nThe following batches will be removed: ", btchs2Remove))
      myBatches <- myBatches[which(!myBatches %in% btchs2Remove)]
    }
    #
    btchDir <- paste0(dstDir, "/Batch correction")
    if (!dir.exists(btchDir)) { dir.create(btchDir, recursive = TRUE) }
    pkgs <- unique(c(pkgs, "sva", "plotly", "htmlwidgets", "shiny", "shinyjs", "shinycssloaders", "DT", "ggrepel"))
    for (pkg in pkgs) {
      if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
        pak::pkg_install(pkg, ask = FALSE)
      }
    }
    for (pkg in pkgs) {
      library(pkg, character.only = TRUE)
    }
    scoresLst <- PCAlyLst <- PCsLst <- list()
    orig <- "original"
    prevBatch <- sapply(myBatches, function(btch) {
      m <- match(btch, myBatches)
      if (m == 1) {
        rs <- orig
      } else {
        rs <- myBatches[m - 1]
      }
      return(rs)
    })
    #
    # Prepare data
    intCols <- paste0(intRoot[intType], smpls)
    logIntCols <- gsub(proteoCraft::topattern(intRoot[intType]), logIntRoot[intType], intCols)
    edata <- pep[, intCols]
    for (k in intCols) {
      edata[[k]] <- log10(edata[[k]])
    }
    colnames(edata) <- logIntCols
    grps <- smplsMap$Group[match(smpls, smplsMap$New)]
    #
    # Impute missing values
    tempImp <- proteoCraft::Data_Impute2(edata, grps)
    impEdata <- tempImp$Imputed_data
    impVal <- tempImp$Positions_Imputed
    #
    # First let's look at the pre-batch correction data with PCA plots:
    tst <- try(pcaBatchPlots, silent = TRUE)
    if ("try-error" %in% class(tst)) {
      source("H:/aRmel_package/proteoCraft/R/pcaBatchPlots.R")
    }
    tmp <- pcaBatchPlots(impEdata,
                         orig,
                         intRoot = logIntRoot[intType],
                         map = smplsMap,
                         SamplesCol = "New")
    PCAlyLst[[orig]] <- tmp$PlotLy
    scoresLst[[orig]] <- tmp$Scores
    PCsLst[[orig]] <- tmp$PCs
    #
    mod0 <- model.matrix(~1, data = smplsMap)
    mod <- model.matrix(~as.factor(smplsMap$Group), data = smplsMap)
    n.sv <- sva::num.sv(impEdata, mod, method = "leek")
    KeepComBatResDflt <- (n.sv > 0)
    if (n.sv == 0) {
      msg <- "We do not estimate that there are any surrogate variables hidden in the data -> no batch correction required. Correct nonetheless?"
      opt <- c("No                                                                                                                                                                                                                                                                                                                ",
               "Yes                                                                                                                                                                                                                                                                                                               ")
      combatNorm <- c(FALSE, TRUE)[match(dlg_list(opt, opt[1], title = msg)$res, opt)]
    }
  }
  if (combatNorm) {
    ComBat_Data <- list()
    KeepComBatRes <- c()
    for (btch in myBatches) { #btch <- myBatches[1] #btch <- myBatches[2]
      keepCmBtRs <- KeepComBatResDflt
      combat_edata <- list()
      for (grp in Groups) { #grp <- Groups[1]
        last <- btch
        prev <- prevBatch[btch]
        w <- which(smplsMap$Group == grp)
        k <- paste0(logIntRoot[intType], smplsMap$New[w])
        mod0a <- model.matrix(~1, data = smplsMap[w,])
        combat_edata[[grp]] <- ComBat(dat = impEdata[, k],
                                      batch = smplsMap[[btch]][w],
                                      mod = mod0a,
                                      par.prior = TRUE)
      }
      combat_edata <- do.call(cbind, combat_edata)
      combat_edata <- as.data.frame(combat_edata)
      # Plot
      tmp <- pcaBatchPlots(combat_edata,
                           btch,
                           intRoot = logIntRoot[intType],
                           map = smplsMap,
                           SamplesCol = "New")
      PCAlyLst[[btch]] <- tmp$PlotLy
      scoresLst[[btch]] <- tmp$Scores
      PCsLst[[btch]] <- tmp$PCs
      #
      appNm <- paste0("Batch corr.: ", prev, " -> ", btch)
      msg <- "Keep results from ComBat batch correction? (untick to cancel correction)"
      PCs <- data.frame("Component" = paste0("PC", as.character(1:length(PCsLst[[prev]]$sdev))),
                        "Before (%)" = round(100*(PCsLst[[prev]]$sdev)^2 / sum(PCsLst[[prev]]$sdev^2), 0),
                        "After (%)" = round(100*(PCsLst[[btch]]$sdev)^2 / sum(PCsLst[[btch]]$sdev^2), 0))
      if (exists("IHAVERUN")) { rm(IHAVERUN) }
      ui <- fluidPage(
        useShinyjs(),
        setBackgroundColor( # Doesn't work
          color = c(#"#F8F8FF",
            "#EEFAE6"),
          gradient = "linear",
          direction = "bottom"
        ),
        extendShinyjs(text = jsToggleFS, functions = c("toggleFullScreen")),
        tags$head(tags$style(HTML("table {table-layout: fixed;"))), # So table widths can be properly adjusted!
        titlePanel(tag("u", appNm),
                   appNm),
        br(),
        fluidRow(column(5,
                        checkboxInput("KeepResults", msg, keepCmBtRs),
                        actionBttn("saveBtn", "Save", icon = icon("save"), color = "success", style = "pill"),
                        h4("Recommended criteria:"),
                        h5(HTML("&nbsp;Does the original grouping follow known batches?")),
                        h5(HTML("&nbsp;&nbsp;-> If no: only accept the correction if it improves the apparent grouping of expected sample groups.")),
                        h5(HTML("&nbsp;&nbsp;-> If yes: accept the correction if...")),
                        h5(HTML("&nbsp;&nbsp;&nbsp;- ... it removes the original grouping by batches...")),
                        h5(HTML("&nbsp;&nbsp;&nbsp;- ... or it improves the apparent grouping of expected sample groups.")),
                        withSpinner(DTOutput("PCs")),
                        br(),
                        br(),
                        br()),
                 column(7,
                        withSpinner(plotlyOutput("Before", height = "550px")),
                        withSpinner(plotlyOutput("After", height = "550px")))),
        br(),
        br()
      )
      server <- function(input, output, session) {
        output$Before <- renderPlotly(PCAlyLst[[prev]][[btch]])
        output$After <- renderPlotly(PCAlyLst[[btch]][[btch]])
        output$PCs <- renderDT({ PCs },
                               FALSE,
                               escape = FALSE,
                               selection = "none",
                               editable = FALSE,
                               rownames = FALSE,
                               options = list(
                                 dom = 't',
                                 paging = FALSE,
                                 ordering = FALSE
                               ),
                               callback = JS("table.rows().every(function(i, tab, row) {
        var $this = $(this.node());
        $this.attr('id', this.data()[0]);
        $this.addClass('shiny-input-container');
      });
      Shiny.unbindAll(table.table().node());
      Shiny.bindAll(table.table().node());"))
        observeEvent(input[["KeepResults"]], {
          assign("keepCmBtRs", as.logical(input[["KeepResults"]]), envir = .GlobalEnv)
        })
        observeEvent(input$saveBtn, {
          assign("keepCmBtRs", as.logical(input[["KeepResults"]]), envir = .GlobalEnv)
          assign("IHAVERUN", TRUE, .GlobalEnv)
          stopApp()
        })
        #observeEvent(input$cancel, { stopApp() })
        session$onSessionEnded(function() { stopApp() })
      }
      runKount <- 0
      while ((!runKount)||(!exists("IHAVERUN"))) {
        eval(parse(text = runApp), envir = .GlobalEnv)
        runKount <- runKount+1
      }
      #
      msg <- paste0(" -> correction of ", btch, "-batch associated effect from ", prev, " ", c("rejec", "accep")[keepCmBtRs+1], "ted.\n")
      if (!keepCmBtRs) {
        last <- prev
        m <- match(btch, myBatches)
        if (m < length(myBatches)) {
          prevBatch[m+1] <- prev
        }
      }
      cat(msg)
      ComBat_Data[[btch]] <- combat_edata
      KeepComBatRes[btch] <- keepCmBtRs
    }
    w <- which(KeepComBatRes)
    if (length(w)) {
      # If accepted batch correction, we must now put the data back into our pep object
      #
      btch <- names(KeepComBatRes)[max(which(KeepComBatRes))]
      btchCorrData <- ComBat_Data[[btch]]
      # New expression column root names
      intType <- "ComBat"
      intRoot["ComBat"] <- "ComBat corr. int. - "
      logIntRoot["ComBat"] <- "ComBat corr. log10(int.) - "
      # De-log
      for (k in logIntCols) {
        btchCorrData[[k]] <- 10^(btchCorrData[[k]])
      }
      colnames(btchCorrData) <- gsub(proteoCraft::topattern(logIntRoot["Original"]),
                                     intRoot["ComBat"],
                                     colnames(btchCorrData))
      # Re-introduce missing values
      w <- which(impVal, arr.ind = TRUE)
      btchCorrData[w] <- pep[, intCols][w]
      #View(pep[, intCols]);View(btchCorrData)
      #
      comBatCols <- colnames(btchCorrData)
      pep[, comBatCols] <- btchCorrData[, comBatCols]
      normSummary[[intType]] <- sapply(smpls, function(x) { median(pep[[paste0(intRoot[intType], x)]], na.rm = TRUE) })
    }
  }
}

# Define Core peptides as peptides matching the non-tail ordered region of histones 
pep$isCore <- FALSE
w <- which(nchar(pep$`Histone(s)`) > 0)
tmp <- listMelt(Ordered$Ordered, Ordered$Accession, c("Ordered", "Accession"))
tmp$Ordered <- paste0("_", unlist(tmp$Ordered), "_")
# We will define a peptide as Core if, for each core histone it matches, it's match falls entirely within the ordered region
pep$tmp <- strsplit(pep$`Histone(s)`, ";")
pep$isCore[w] <- apply(pep[w, c("Sequence", "tmp")], 1, function(x) { #x <- pep[w[1], c("Sequence", "tmp")]
  sq <- tmp$Ordered[match(unlist(x[[2]]), tmp$Accession)]
  sq <- strsplit(sq, unlist(x[[1]]))
  tst <- sapply(sq, length)
  return(min(tst) > 1)
})
pep$tmp <- NULL

# Normalize
quntCol <- paste0(intRoot[intType], smpls)
if (length(Exp) > 1) {
  normOpt <- c("Histone-fold region of all core histones",
               "Histone-fold region of all core histones, per histone (-> non-histone peptides excluded from analysis!)",
               "All proteins",
               "Do not normalize")
  opt2 <- setNames(sapply(normOpt, function(x) { paste(c(x, rep(" ", 150 - nchar(x))), collapse = "") }), normOpt)
  normMeth <- dlg_list(opt2, opt2[1], title = "Select which normalization method you wish to use")$res
  normMeth <- names(opt2[match(normMeth, opt2)])
  if (normMeth %in% normOpt[1:3]) {
    intRoot["Normalized"] <- "norm. int. - "
    logIntRoot["Normalized"] <- "norm.  log10(int.) - "
    quntCol2 <- paste0(intRoot["Normalized"], smpls)
    if (normMeth %in% normOpt[1:2]) {
      w <- which(pep$isCore)
      if (!length(w)) { stop("Not enough peptides to normalize") }
      pep$isModified <- gsub("^_|_$", "", pep$`Modified sequence`) != pep$Sequence
      tst <- sum(!pep$isModified[w])
      if (tst) {
        msg <- paste0("Should we exclude modified peptides from the set used for normalization?\n(out of a total of ", length(w), " histone ordered region peptidoforms, ", tst, " are unmodified)")
        removeMods <- c(TRUE, FALSE)[match(dlg_message(msg, "yesno")$res, c("yes", "no"))]
        if (removeMods) {
          w <- w[which(!pep$isModified[w])]
        }
      }
      # Global normalisation to histones
      #View(pep[w, c("id", quntCol)])
      tmp <- proteoCraft::AdvNorm.IL(pep[w, c("id", quntCol)], "id", quntCol)
      #View(tmp)
      #tst <- sapply(paste0("AdvNorm.", quntCol), function(x) { summary(tmp[[x]]) });View(tst)
      x <- unlist(pep[w, quntCol])
      x <- x[which(x > 0)]
      M <- median(x, na.rm = TRUE)
      m <- sapply(paste0("AdvNorm.", quntCol), function(x) {
        x <- unlist(tmp[[x]])
        x <- x[which(x > 0)]
        median(is.all.good(as.numeric(x)))
      })
      pep[, quntCol2] <- sweep(pep[, quntCol], 2, m, "/")*M
      if (normMeth == normOpt[2]) {
        # Here we want to normalize each peptide to the parent protein(s)
        # I guess we can calculate normalization factors for each unique protein,
        # then average those if a peptide matches several proteins?
        w <- which(pep$`Histone(s)` != "")
        prt2pep <- proteoCraft::listMelt(strsplit(pep$Proteins[w], ";"), w, c("Protein", "pepRow"))
        prt2pep <- aggregate(prt2pep$pepRow, list(prt2pep$Protein), list)
        prt2pep$id <- sapply(prt2pep$x, function(x) { pep$id[unlist(x)] })
        prt2pep$Core <- sapply(prt2pep$id, function(x) {
          x[which(pep$isCore[match(x, pep$id)])]
        })
        wL <- which(sapply(prt2pep$Core, length) > 0)
        prt2pep <- prt2pep[wL,]
        # Calculate Core peptides-only re-normalization factor at protein level:
        #prt2pep$Norm <- lapply(1:nrow(prt2pep), function(x) { c() })
        tmp <- pep[, c("id", quntCol2)]
        clusterExport(parClust, list("tmp", "quntCol2", "smpls"), envir = environment())
        prt2pep[, smpls] <- as.data.frame(t(parSapply(parClust, prt2pep$Core, function(x) { #x <- prt2pep$Core[2]
          tmp1 <- tmp[match(unlist(x), tmp$id),]
          M <- unlist(tmp1[, quntCol2])
          M <- M[which(M > 0)]
          M <- median(M, na.rm = TRUE)
          tmp1 <- proteoCraft::AdvNorm.IL(tmp1, "id", quntCol2)
          #View(tmp)
          #tst <- sapply(paste0("AdvNorm.", quntCol2), function(x) { summary(tmp[[x]]) });View(tst)
          m <- sapply(paste0("AdvNorm.", quntCol2), function(x) {
            x <- unlist(tmp1[[x]])
            x <- x[which(x > 0)]
            median(proteoCraft::is.all.good(as.numeric(x)))
          })
          return(setNames(M/m, smpls)) 
        })))
        #
        # Turn it into peptide-level normalization factors, averaging as needed
        pep2prt <- listMelt(prt2pep$x, prt2pep$Group.1, c("pep", "prot"))
        pep2prt[, smpls] <- prt2pep[match(pep2prt$prot, prt2pep$Group.1[wL]), smpls]
        Norm <- aggregate(pep2prt[, smpls], list(pep2prt$pep), function(x) { exp(mean(log(x), na.rm = TRUE)) })
        # If we cannot calculate a normalization factor, we need to remove the peptide
        tst <- parApply(parClust, Norm[, smpls], 1, function(x) { length(proteoCraft::is.all.good(x)) })
        Norm <- Norm[which(tst > 0),]
        #
        # Now we need to remove peptides which cannot be normalized with this method
        wN <- which(!pep$id %in% Norm$Group.1)
        wY <- which(pep$id %in% Norm$Group.1)
        warning(paste0("Removing ", length(w), " non-normalizable peptides (keeping ", length(wY), ")"))
        pep <- pep[wY,]
        Norm <- Norm[match(pep$id, Norm$Group.1),]
        #
        # Finally we apply the normalization
        for (i in 1:length(smpls)) {
          pep[[quntCol2[i]]] <- pep[[quntCol2[i]]]*Norm[[smpls[i]]]
        }
      }
    }
    if (normMeth == normOpt[3]) {
      tmp <- proteoCraft::AdvNorm.IL(pep[, c("id", quntCol)], "id", quntCol)
      pep[, quntCol2] <- tmp[, paste0("AdvNorm.", quntCol)]
    }
    intType <- "Normalized"
    normSummary[[intType]] <- sapply(smpls, function(x) { median(pep[[paste0(intRoot[intType], x)]], na.rm = TRUE) })
    quntCol <- paste0(intRoot[intType], smpls) # Update
  }
}

# Look at shift induced by normalization for all samples
normTst <- data.frame(Sample = smpls, NormFact = round(normSummary[[intType]]/normSummary$Original, 3))
max(normTst$NormFact)/min(normTst$NormFact)
write.csv(normTst, paste0(dstDir, "/Norm. summary.csv"), row.names = FALSE)
#tmp <- paste0(do.call(paste, c(normTst, sep = " ->\t\t")), "\n")
#writeClipboard(capture.output(cat(tmp)))

# Table of PTM sites
kol <- c("Sequence", "Modified sequence_verbose", "Proteins")
w <- which((kol %in% colnames(ev))&(!kol %in% colnames(evSum)))
if (length(w)) { evSum[, kol[w]] <- ev[match(evSum$`Modified sequence`, ev$`Modified sequence`), kol[w]] }
w <- which((kol %in% colnames(evSum))&(!kol %in% colnames(pep)))
if (length(w)) { pep[, kol[w]] <- evSum[match(pep$`Modified sequence`, evSum$`Modified sequence`), kol[w]] }
tmp <- pep[, kol]
tmp$`Modified sequence_verbose` <- gsub("^_|_$", "", tmp$`Modified sequence_verbose`)
w <- which(tmp$Proteins == "")
tmp$Proteins[w] <- "No match!"
tst <- do.call(paste, c(tmp, sep = "///"))
tst <- unique(tst)
tmp <- Isapply(strsplit(tst, split = "///"), unlist)
colnames(tmp) <- kol
tmp$pepID <- pep$id
tmp2 <- unlist(strsplit(tmp$Proteins, ";"))
tmp2 <- aggregate(tmp2, list(tmp2), length)
tmp2 <- tmp2[order(tmp2$x, decreasing = TRUE),]
clusterExport(parClust, "tmp2", envir = environment())
tmp$Proteins_by_pep <- parSapply(parClust, strsplit(tmp$Proteins, ";"), function(x) { #x <- strsplit(tmp$Proteins[5], ";")
  x <- unlist(x)
  if (length(x) > 1) {
    o <- tmp2$x[match(x, tmp2$Group.1)]
    x <- x[order(o, decreasing = TRUE)]
    x <- paste(sort(unlist(x)), collapse = ";")
  }
  return(x)
})
tmp$First_Protein <- gsub(";.*", "", tmp$Proteins_by_pep)
m <- match(tmp$First_Protein, db$`Protein ID`)
w <- which(!is.na(m))
tmp <- tmp[w,]; m <- m[w]
tmpSq <- paste0("_", db$Sequence[m])
tmp$Match <- sapply(1:nrow(tmp), function(x) {
  nchar(unlist(strsplit(tmpSq[x], tmp$Sequence[x]))[1])
})
tmp$Tbl <- parLapply(parClust, paste0("_", tmp$`Modified sequence_verbose`, "_"), proteoCraft::annot_to_tabl)
tmp$Sites <- lapply(1:nrow(tmp), function(x) { #x <- 1
  # Do not parallelize me: it's slower!
  mtch <- tmp$Match[x]
  pr <- tmp$First_Protein[x]
  tbl <- tmp$Tbl[[x]]
  tbl <- tbl[[1]]
  nr <- nrow(tbl)-2
  tbl$Dist <- c(1, 1:nr, nr)
  tbl$Pos <- tbl$Dist + mtch - 1
  tbl <- tbl[which(tbl$Annotations != ""), , drop = FALSE]
  tbl$Site <- apply(tbl[, c("Sequence", "Pos", "Annotations")], 1, function(y) {
    paste0(pr, " ", y[[1]], y[[2]], "(", y[[3]], ")")
  })
  return(tbl$Site)
})
Sites <- listMelt(tmp$Sites, tmp$pepID, c("Site", "pepID"))
quntCol <- paste0(intRoot[intType], smpls) # Update
Sites[, quntCol] <- pep[match(Sites$pepID, pep$id), quntCol]
Sites2 <- Sites
Sites2$pepID <- NULL
Sites2 <- as.data.table(Sites2)
Sites2 <- Sites2[, lapply(.SD, sum, na.rm = TRUE), keyby = Site]
Sites2 <- as.data.table(Sites2)
Sites2 <- Sites2[, lapply(.SD, sum, na.rm = TRUE), keyby = Site] # NB: converts all NAs to 0... equivalent but we had NAs, I will re-introduce them
Sites2 <- as.data.frame(Sites2)
w <- which(as.matrix(Sites2[, quntCol]) == 0, arr.ind = TRUE)
Sites2[, quntCol][w] <- NA
Sites2$Type <- gsub(".*\\(|\\)", "", Sites2$Site)
Sites2$Protein <- gsub(" .*", "", Sites2$Site)
Sites$`Histone(s)` <- pep$`Histone(s)`[match(Sites$pepID, pep$id)]
Sites2$`Histone(s)` <- Sites$`Histone(s)`[match(Sites2$Site, Sites$Site)]
Sites2$Protein_name <- db$`Common Name`[match(Sites2$Protein, db$`Protein ID`)]
Sites <- Sites2; rm(Sites2)
labCol <- c("Site", "Protein_name")
Sites$Label <- apply(Sites[, labCol], 1, function(x) {
  paste0(labCol, ": ", x, collapse = "\n")
})

if (statTsts) {
  # Statistics
  a <- 1
  tst <- try(clusterExport(parClust, "a", envir = environment()), silent = TRUE)
  if ("try-error" %in% class(tst)) {
    try(stopCluster(parClust), silent = TRUE)
    parClust <- makeCluster(N.clust, type = "SOCK")
  }
  #
  clusterExport(parClust, list("Nested"), envir = environment())
  #reNorm <- FALSE
  
  # From smplsMap to design matrix
  smplsMap$Sample <- smplsMap$New
  Factors2 <- c("Group")
  Factors <- c("Sample", "Replicate", Factors2)
  for (fct in Factors) {
    assign(paste0(fct, "_"), as.factor(smplsMap[[fct]]))
  }
  if (Nested) {
    designCall <- paste0("designMatr <- model.matrix(~0 + Replicate_ + ", paste0(Factors2, "_", collapse = " + "), ")")
  } else {
    designCall <- paste0("designMatr <- model.matrix(~0 + ", paste0(Factors2, "_", collapse = " + "), ")")
  }
  #cat(designCall, "\n")
  eval(parse(text = designCall))
  #
  # Define contrasts
  expContrasts <- list()
  for (ratGrp in compGrps) {
    em <- smplsMap[which(smplsMap$Comparison_group == ratGrp),]
    grp1 <- unique(em$Group[which(!em$Reference)])
    grp0 <- unique(em$Group[which(em$Reference)])
    expContrasts[[ratGrp]] <- plyr::rbind.fill(lapply(grp0, function(g0) { data.frame(x1 = paste0("Group_", grp1), x0 = paste0("Group_", g0)) }))
  }
  expContrasts <- plyr::rbind.fill(expContrasts)
  tmp <- expContrasts
  w <- which(!tmp$x1 %in% colnames(designMatr))
  if (length(w)) { tmp$x1[w] <- "" }
  w <- which(!tmp$x2 %in% colnames(designMatr))
  if (length(w)) { tmp$x2[w] <- "" }
  tmp <- apply(tmp, 1, function(x) {
    #x <- x[which(x != "")]
    if (length(x) == 2) { x <- paste(x, collapse = " - ") }
    return(x)
  })
  contrCall <- paste0("contrMatr <- makeContrasts(",
                      paste(tmp, collapse = ", "),
                      ", levels = designMatr)")
  # (NB: these could be renamed to something shorter, e.g. makeContrasts(Comp1 = A - B, Comp2 = A - C)
  #cat(contrCall, "\n")
  eval(parse(text = contrCall))
  expContrasts$Name <- colnames(contrMatr)
  #
  colMatch <- data.frame(x = c("up", "down", "n.s.", "n.t."),
                         y = c(1, -1, 0, NA))
  myColors <- setNames(c("limegreen","red3", "black", "grey"),
                       c("up", "down", "n.s.", "n.t."))
  colScale <- scale_colour_manual(name = "colour", values = myColors)
  #
  FDR <- 0.3
  FC <- 1.5
  l10FC <- log10(FC) # For decideTests, to which we feed log10 data and so which needs a log10 FC!
  l2FC <- log2(FC) # For plotting
  statsXprs <- expression({
    intCols <- grep(intRoot[intType], colnames(myData), value = TRUE)
    w <- which(myData[, intCols] == 0, arr.ind = TRUE)
    if (nrow(w)) {
      myData[, intCols][w] <- NA
    }
    myData[, gsub(intRoot[intType],
                  logIntRoot[intType],
                  intCols)] <- log10(myData[, intCols])
    #
    # First calculate mean per group
    for (grp in Groups) { #grp <- Groups[1] #grp <- Groups[2]
      #cat(" - Mean intensities ", grp, "\n")
      w <- which(smplsMap$Group == grp)
      e1 <- smplsMap[w,]
      stopifnot(length(unique(e1$New)) == length(e1$New))
      smpls1 <- e1$New
      col1 <- paste0(logIntRoot[intType], smpls1)
      w1 <- which(col1 %in% colnames(myData))
      if (length(w1)) { # Calculate average expression
        e1 <- e1[w1,]; col1 <- col1[w1]
        ke1 <- paste0("Mean ", logIntRoot[intType], grp)
        tempVal <- myData[, col1, drop = FALSE]
        row.names(tempVal) <- myData[[namesCol]]
        if (length(w1) == 1) {
          cat(paste0("Warning: Only 1 replicate for ", grp, "!\n"))
          myData[[ke1]] <- tempVal[[1]]
        } else {
          myData[[ke1]] <- parApply(parClust, tempVal, 1, mean, na.rm = TRUE)
        }
      }
    }
    rm(grp)
    #
    # Average lfc
    if (Nested) {
      for (contr in colnames(contrMatr)) { #contr <- colnames(contrMatr)[1] #contr <- colnames(contrMatr)[2]
        tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
        e <- smplsMap[which(smplsMap$Group %in% tmp),]
        uRps <- unique(e$Replicate)
        rps <- lapply(uRps, function(x) {
          x0 <- e$New[which((e$Replicate == x)&(e$Reference))]
          x1 <- e$New[which((e$Replicate == x)&(!e$Reference))]
          if ((length(x0) == 1)&&(length(x1) == 1)) {
            rs <- data.frame(Rep = x,
                             Ref = x0,
                             Sample = x1)
          } else {
            rs <- data.frame(Rep = x,
                             Ref = NA,
                             Sample = NA)
          }
          return(rs)
        })
        rps <- plyr::rbind.fill(rps)
        rps <- rps[which(!is.na(rps$Ref)),]
        rps <- rps[which(!is.na(rps$Sample)),]
        myData[, paste0(ratRoot, nm, " ", uRps)] <- cbind(lapply(uRps, function(x) { #x <- uRps[1]
          m <- match(x, rps$Rep)
          (myData[[paste0(logIntRoot[intType], rps$Sample[m])]] - myData[[paste0(logIntRoot[intType], rps$Ref[m])]])/log10(2)
        }))
        myData[[paste0(ratRoot, nm)]] <- apply(myData[, paste0(ratRoot, nm, " ", uRps)], 1, mean, na.rm = TRUE)
      }
    } else {
      myData[, paste0(ratRoot, gsub("Group_", "", colnames(contrMatr)))] <- cbind(lapply(1:nrow(expContrasts), function(x) { #x <- 1
        x <- gsub("^Group_", "", expContrasts[x,])
        (myData[[paste0("Mean ", logIntRoot[intType], x[1])]] - myData[[paste0("Mean ", logIntRoot[intType], x[2])]])/log10(2)
      }))
    }
    #View(myData[, c(paste0(logIntRoot[intType], smplsMap$Sample), paste0(ratRoot, gsub("Group_", "", colnames(contrMatr))))])
    #
    tempVal <- myData[, paste0(logIntRoot[intType], smplsMap$Sample)]
    fit <- lmFit(tempVal, designMatr) # It's a nested design
    fit <- contrasts.fit(fit, contrMatr)
    fit <- eBayes(fit) # Assumes 1% of genes change!!!
    #View(fit$p.value)
    pVal <- fit$p.value
    kol2 <- sapply(colnames(pVal), function(contr) { #contr <- colnames(pVal)[2]
      tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
      nm <- paste(tmp, collapse = " - ")
      return(paste0("Mod. P-value - ", nm))
    })
    myData[, kol2] <- pVal
    FDR_thresh <- list()
    for (i in 1:ncol(pVal)) {
      contr <- colnames(contrMatr)[i]
      tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
      nm <- paste(tmp, collapse = " - ")
      sig <- proteoCraft::FDR(as.data.frame(pVal),
                              pvalue_col = colnames(pVal)[i],
                              fdr = 30,
                              returns = c(TRUE, TRUE))
      #View(sig$`Significance vector`)
      myData[[paste0("Signif. - ", nm)]] <- sig$`Significance vector`
      FDR_thresh[[nm]] <- sig$Thresholds
    }
    decisions <- decideTests(fit, adjust.method = "BH", p.value = FDR, lfc = l10FC) # Remember! The log base of the lfc threshold must be the same as that of the input data!!!
    decisions <- as.data.frame(decisions@.Data)
    nms <- sapply(colnames(decisions), function(contr) { #contr <- colnames(decisions)[2]
      tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
      nm <- paste(tmp, collapse = " - ")
      return(nm)
    })
    kol2 <- paste0("Decision - ", nms)
    colnames(decisions) <- nms
    myData[, kol2] <- decisions
    venn <- vennCounts(decisions)
    print(venn)
    #
    for (contr in colnames(contrMatr)) { #contr <- colnames(contrMatr)[2]
      tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
      nm <- paste(tmp, collapse = " - ")
      dc <- paste0("Decision - ", nm)
      myData[[dc]] <- colMatch$x[match(myData[[dc]], colMatch$y)]
    }
    myData$"is Histone" <- c("-", "+")[(myData$`Histone(s)` != "") + 1]
    myData$"is Histone"[which(is.na(myData$"is Histone"))] <- "-"
    myData$Alpha <- c(0.2, 1)[match(myData$"is Histone", c("-", "+"))]
    myData$Size <- c(0.1, 1.5)[match(myData$"is Histone", c("-", "+"))]
    for (contr in colnames(contrMatr)) { #contr <- colnames(contrMatr)[2]
      tmp <- gsub("Group_", "", expContrasts[match(contr, expContrasts$Name), c("x1", "x0")])
      nm <- paste(tmp, collapse = " - ")
      thresh <- FDR_thresh[[nm]]
      ttl <- paste0(namesRoot, " ", nm)
      fc <- paste0(ratRoot, nm)
      pv <- paste0("Mod. P-value - ", nm)
      dc <- paste0("Decision - ", nm)
      plot <- ggplot(myData) +
        geom_point(aes(x = .data[[fc]], y = -log10(.data[[pv]]), colour = .data[[dc]],
                       shape = `is Histone`, alpha = Alpha, size = Size, text = Label)) +
        theme_bw() + ggtitle(ttl) + colScale +
        geom_vline(xintercept = -l2FC, color = "red3", linetype = "dashed") +
        geom_vline(xintercept = l2FC, color = "limegreen", linetype = "dashed") +
        geom_hline(yintercept = -log10(thresh), color = "purple", linetype = "dashed") +
        scale_alpha_identity(guide = "none") + scale_size_identity(guide = "none") +
        scale_y_continuous(expand = c(0, 0))
      #poplot(plot)
      ggsave(paste0(dstDir, "/", ttl, ".jpeg"), plot, dpi = 300)
      plotLy <- ggplotly(plot, tooltip = c("x", "y", "text"))
      htmlwidgets::saveWidget(plotLy, paste0(dstDir, "/", ttl, ".html"), selfcontained = TRUE)
      system(paste0("open \"", dstDir, "/", ttl, ".html\""))
    }
  })
  #
  for (iii in 1:2) { #iii <- 1
    if (iii == 1) {
      myData <- pep
      namesCol <- "Label"
      namesRoot <- "Peptides"
    }
    if (iii == 2) {
      myData <- Sites
      namesCol <- "Site"
      namesRoot <- "Sites"
    }
    eval(statsXprs)
  }
}

# Specific peptides/sites
for (cmpGrp in compGrps) { #cmpGrp <- compGrps[1]
  grps <- unique(grpsMap$Group[which(grpsMap$Comparison_group == cmpGrp)])
  grps2smpls <- setNames(lapply(grps, function(grp) { unique(smplsMap$New[which(smplsMap$Group == grp)]) }), grps)
  grps2kol <- setNames(lapply(grps2smpls, function(x) { paste0(intRoot[intType], x) }), grps)
  stopifnot(sum(!unlist(grps2kol) %in% colnames(pep)) == 0,
            sum(!unlist(grps2kol) %in% colnames(Sites)) == 0)
  for (grp1 in grps) { #grp1 <- grps[1]
    k1 <- grps2kol[[grp1]]
    tst <- grpsMap$Reference[match(grp1, grpsMap$Group)]
    # This will mean comparing to reference
    grp0 <- grpsMap$Group[which((grpsMap$Comparison_group == cmpGrp)&(grpsMap$Reference != tst))]
    k0 <- unlist(grps2kol[grp0])
    pep[[paste0("Specific - ", grp1)]] <- vapply(1:nrow(pep), function(i) {
      x1 <- is.all.good(as.numeric(pep[i, k1]))
      x0 <- is.all.good(as.numeric(pep[i, k0]))
      res <- c("", "+")[(((!length(x0))&(length(x1) >= 3))|((length(x0) == 1)&(length(x1) >= 4))) + 1]
      return(res)
    }, "a")
    Sites[[paste0("Specific - ", grp1)]] <- vapply(1:nrow(Sites), function(i) {
      x1 <- is.all.good(as.numeric(Sites[i, k1]))
      x0 <- is.all.good(as.numeric(Sites[i, k0]))
      res <- c("", "+")[(((!length(x0))&(length(x1) >= 3))|((length(x0) == 1)&(length(x1) >= 4))) + 1]
      return(res)
    }, "a")
  }
}

# Write tables
# - Peptides
smplsMap2 <- smplsMap[order(smplsMap$Comparison_group,
                            smplsMap$Group,
                            smplsMap$Replicate),]
smpls2 <- unique(smplsMap2$New)
Groups2 <- unique(smplsMap2$Group)
kol <- c(paste0(intRoot[intType], smpls2),
         paste0("Specific - ", Groups2))
tmp <- pep[which(pep$`Histone(s)` != ""),]
tmp$Modifications <- gsub(",", ";", tmp$`Modified sequence`)
tmp <- tmp[, c(colnames(tmp)[which(!colnames(tmp) %in% kol)], kol)]
tmp$Label <- gsub("\n", " ", tmp$Label)
fl <- paste0(dstDir, "/Histone peptides.csv")
data.table::fwrite(tmp, fl, quote = FALSE, na = "NA", sep = ",")
#openxlsx2::xl_open(fl)
# - Sites
tmp <- Sites[which(Sites$`Histone(s)` != ""),]
tmp <- tmp[, c(colnames(tmp)[which(!colnames(tmp) %in% kol)], kol)]
tmp$Label <- gsub("\n", " ", tmp$Label)
fl <- paste0(dstDir, "/Histone sites.csv")
data.table::fwrite(tmp, fl, quote = FALSE, sep = ",", na = "NA")
#openxlsx2::xl_open(fl)
#
saveImgFun(backupFl)

#### Heatmaps with clustering
if (length(Exp) > 1) {
  pkgs <- unique(c(pkgs, "ggdendro", "gridExtra", "ggpubr", "colorspace", "ggnewscale", "factoextra", "NbClust"))
  for (pkg in pkgs) {
    if (!require(pkg, character.only = TRUE, quietly = TRUE)) {
      pak::pkg_install(pkg, ask = FALSE)
    }
  }
  for (pkg in pkgs) {
    library(pkg, character.only = TRUE)
  }
  dir <- paste0(dstDir, "/Clustering")
  if (!dir.exists(dir)) { dir.create(dir, recursive = TRUE) }
  xMap <- smplsMap
  #
  ImputeKlust <- TRUE
  MaxHClust <- min(c(floor(nrow(pep)/2), 100)) # We want at most 20 clusters
  MaxVClust <- nrow(grpsMap)
  VClustScl <- setNames(1:MaxVClust, paste0("Cluster", 1:MaxVClust))
  HClustScl <- setNames(1:MaxHClust, paste0("Cluster", 1:MaxHClust))
  VClustScl <- setNames(rainbow(MaxVClust), VClustScl)
  HClustScl <- setNames(rainbow(MaxHClust), HClustScl)
  # Different options for which proteins to use for vertical clustering (samples level)
  KlustMeth <- 2
  KlustRoot <- paste0("Cluster (", c("K-means", "hierarch.")[KlustMeth], ") - ")
  normTypes <- c("Norm. by row", "Z-scored")
  kol <- paste0(intRoot[intType], smpls)
  plotLeatMaps <- list()
  prot.list.Cond <- TRUE
  prot.list <- histDB$`Protein ID`
  KlustKols <- c()
  #
  Filter <- list("Global" = 1:nrow(pep),
                 "Histones only" = which(pep$`Histone(s)` != ""))
  for (normType in normTypes) { #normType <- normTypes[1]
    normTypeInsrt <- c("", paste0(" (", normType, ")"))[match(normType, normTypes)]
    plotLeatMaps[[normType]] <- list()
    for (flt in names(Filter)) {
      fltInsrt <- c("", " Histones only")[match(flt, names(Filter))]
      temp <- magrittr::set_rownames(magrittr::set_colnames(pep[Filter[[flt]], kol], smpls), pep$Label[Filter[[flt]]])
      temp <- log10(temp)
      Gr <- xMap$Comparison_group
      Gr <- setNames(match(Gr, unique(Gr)), Gr)
      tst <- apply(temp, 1, function(x) { length(is.all.good(x)) })
      filt <- rep(FALSE, nrow(temp))
      temp <- temp[which(tst > 0),]
      if (ImputeKlust) {
        temp2 <- Data_Impute2(temp, Gr)
        imputed <- temp2$Positions_Imputed
        temp <- temp2$Imputed_data
        rownames(imputed) <- rownames(temp)
        colnames(imputed) <- colnames(temp)
      }
      w <- which(apply(temp, 1, function(x) { length(is.all.good(x)) }) == length(kol))
      filt[which(tst > 0)[w]] <- TRUE
      temp <- temp[w,]
      imputed <- imputed[w,]
      rwMns <- rowMeans(temp)
      if (normType == "Norm. by row") {
        temp <- sweep(temp, 1, rwMns, "-")
      }
      if (normType == "Z-scored") {
        SDs <- apply(temp, 1, function(x) { sd(is.all.good(x)) })
        temp <- sweep(sweep(temp, 1, rwMns, "-"), 1, SDs, "/")
      }
      temp2 <- temp3 <- as.matrix(temp) + runif(length(temp), min = 0, max = 1e-10) # Small error added to avoid duplicate rows where this breaks
      # Data is now normalized and either imputed or filtered, so ready for clustering
      # 1/ At samples level
      # We perform hierarchical clustering in all cases, because we want to see the dendrogram.
      # But the clusters displayed using colours may be generated using either k-means or hierarchical clustering (default).
      temp2 <- t(temp2)
      tst2 <- apply(temp2, 2, function(x) {
        #x <- is.all.good(x) # it's been imputed, there are no missing values
        sd(x)/mean(x)
      })
      temp2 <- temp2[, order(tst2, decreasing = TRUE)]
      vcluster <- hclust(dist(temp2))
      vdendro <- as.dendrogram(vcluster)
      # Estimate ideal number of clusters... but ignore it!
      # In fact we know the number of sample groups, so would like to see 1 cluster per group.
      # How well groups and clusters overlap would tell us how well the clustering works, i.e. how different clusters are.
      #
      # Here we use kmeans, but findings apply to any method
      #cat("Estimating optimal number of samples-level clusters...\n")
      vnm <- paste0("Samples-level clusters number analysis", fltInsrt)
      NVClust <- NGr <- length(unique(Gr))
      tst <- cluster::clusGap(temp2, kmeans, min(c(nrow(temp2), NGr+1)))
      tst2 <- as.data.frame(tst$Tab)
      yScl <- max(tst2$gap)
      tst2 <- sapply(1:NGr, function(x) { tst2$gap[x] >= tst2$gap[x+1] - tst2$SE.sim[x+1] })
      tst2 <- which(tst2)
      # I like to do one more, often these methods feel too conservative
      #if (length(tst2)) { NVClust <- tst2[1]+1 } # Not used for now: we use NGr instead
      vplot <- fviz_gap_stat(tst)
      tstLy <- capture.output(print(vplot$layers))
      g1 <- grep("geom_vline", tstLy)
      g2 <- grep("\\[\\[[0-9]+\\]\\]", tstLy)
      g2 <- as.numeric(gsub("\\[|\\]", "", tstLy[max(g2[which(g2 < g1)])]))
      vplot$layers[[g2]] <- NULL
      vplot <- vplot +
        geom_vline(xintercept = tst2[1]+1, colour = "red", linetype = "dashed") +
        geom_vline(xintercept = NGr, colour = "orange", linetype = "dashed") +
        geom_text(label = "Optimal number of sample clusters", x = tst2[1]+1-0.2, y = yScl*0.9,
                  colour = "red", angle = 90, hjust = 1) +
        geom_text(label = "Number of sample groups", x = NGr+0.2, y = yScl*0.9,
                  colour = "orange", angle = 90, hjust = 1) +
        theme_bw() + ggtitle(vnm)
      #poplot(vplot)
      ggsave(paste0(dir, "/", vnm, normTypeInsrt, ".jpeg"), vplot, dpi = 150)
      ggsave(paste0(dir, "/", vnm, normTypeInsrt, ".pdf"), vplot, dpi = 150)
      NVClust <- max(c(NGr, 2))
      # 2/ At protein groups level
      # As above, we always draw a dendrogram, but colours will be defined by the clustering approach.
      hcluster <- hclust(dist(temp3))
      hdendro <- as.dendrogram(hcluster)
      hnm <- paste0("Protein groups-level clusters number analysis", fltInsrt)
      NHClust <- MaxHClust
      Straps <- 10
      # Here we really want to optimize the number of clusters
      # Apply the same method for optimization for any clustering method
      # Number of cluster should not depend on method
      clusterExport(parClust, list("temp3", "Straps"), envir = environment())
      tst <- parSapply(parClust, 2:MaxHClust, function(kl) {
        kmeans(temp3, kl, nstart = Straps)$tot.withinss
      })/kmeans(temp3, 1, nstart = 1)$tot.withinss
      yScl2 <- max(tst)
      tst2 <- data.frame("Number of clusters k" = 2:MaxHClust,
                         "[tot WSS (k)]/[tot WSS (1)]" = tst,
                         check.names = FALSE)
      # For the elbow detection method, we need to normalize to a 1x1 graph which we can rotate by 45 degrees
      tst2$X1 <- tst2$`Number of clusters k`/MaxHClust # divide by max theoretical number of clusters 
      tst2$Y1 <- tst2$"[tot WSS (k)]/[tot WSS (1)]" # Here no need to normalize, this is a ratio
      Angle <- -pi/4
      meanX <- mean(tst2$X1)
      meanY <- mean(tst2$Y1)
      tst2$X2 <- tst2$X1 - meanX
      tst2$Y2 <- tst2$Y1 - meanY
      tst2$X2 <- tst2$X2*cos(Angle)+tst2$Y2*sin(Angle)
      tst2$Y2 <- -tst2$X2*sin(Angle)+tst2$Y2*cos(Angle)
      tst2$X2 <- tst2$X2 - mean(tst2$X2) + meanX
      tst2$Y2 <- tst2$Y2 - mean(tst2$Y2) + meanY
      w <- rev(which(tst2$Y2 == min(tst2$Y2)))[1] # Again, prefer more rather than fewer clusters
      NHClust <- tst2$`Number of clusters k`[w]
      tst2$Size <- 1
      tst2$Size[w] <- 2
      xMin <- min(c(tst2$X1, tst2$X2))
      xMax <- max(c(tst2$X1, tst2$X2))
      xScl <- xMax-xMin
      yMin <- min(c(tst2$Y1, tst2$Y2))
      yMax <- max(c(tst2$Y1, tst2$Y2))
      yScl <- yMax-yMin
      hplot <- ggplot(tst2) +
        geom_segment(x = tst2$X2[w], y = tst2$Y2[w],
                     xend = tst2$X1[w], yend = tst2$Y1[w], color = "grey", linetype = "dotted") +
        geom_point(aes(x = X1, y = Y1, size = Size), color = "blue") +
        geom_point(aes(x = X2, y = Y2, size = Size), color = "red") +
        geom_text(x = xScl*0.98+xMin, y = yMin+yScl*0.98, color = "blue", label = "ratio of tot. WSS", hjust = 1) +
        geom_text(x = xScl*0.98+xMin, y = yMin+yScl*0.962, color = "red", label = "ratio of tot. WSS, -pi/4 rotation", hjust = 1) +
        geom_hline(yintercept = tst2$Y2[w], color = "red", linetype = "dashed") +
        geom_vline(xintercept = tst2$X1[w], color = "deepskyblue", linetype = "dashed") +
        geom_text(x = xMin+0.01*xScl, y = tst2$Y2[w]+0.02*yScl, color = "red", label = "Elbow", hjust = 0) +
        geom_text(x = tst2$X1[w]-0.02*xScl, y = yScl*0.9, angle = 90, color = "deepskyblue",
                  label = paste0("Optimal = ", tst2$`Number of clusters k`[w], " clusters"), hjust = 1) +
        ggtitle(hnm) + scale_size_identity() + theme_bw() +
        theme(legend.position = "none") + ylab("Normalised total Within-clusters vs Total Sum of Squares")
      #poplot(hplot)
      ggsave(paste0(dir, "/", hnm, normTypeInsrt, ".jpeg"), hplot, dpi = 150)
      ggsave(paste0(dir, "/", hnm, normTypeInsrt, ".pdf"), hplot, dpi = 150)
      # Apply cutoffs
      if (KlustMeth == 1) {
        VClusters <- kmeans(t(temp3), NVClust, 100)$cluster
        tempClust <- kmeans(temp3, NHClust, 100)$cluster
      }
      if (KlustMeth == 2) {
        VClusters <- cutree(vcluster, NVClust)
        tempClust <- cutree(hcluster, NHClust)
      }
      KlKol <- KlustRoot
      KlustKols <- unique(c(KlustKols, KlKol))
      pep[[KlKol]] <- tempClust[match(pep$Label, names(tempClust))]
      #
      Width <- nrow(temp)
      Height <- ncol(temp)
      #
      whImps <- which(imputed, arr.ind = TRUE)
      temp[whImps] <- NA
      #
      # Get dendrograms
      vddata <- dendro_data(vdendro)
      hddata <- dendro_data(hdendro)
      # vdendro.plot <- ggdendrogram(data = vdendro) +
      #   theme(axis.text.y = element_text(size = 0.1), plot.margin = margin(0, 0, 0, 0, "cm"))
      # poplot(vdendro.plot)
      # Modify dendrograms
      # - Vertical
      vlabs <- ggdendro::label(vddata)
      vlabs$Cluster <- as.factor(VClusters[match(vlabs$label, smpls)])
      vSeg <- vddata$segments
      # - Horizontal
      hlabs <- ggdendro::label(hddata)
      hlabs$Cluster <- as.factor(tempClust[match(hlabs$label, names(tempClust))])
      hSeg <- hddata$segments
      # Rotate samples-level dendrogram: x -> y, y -> x (for ease of calculation, gets inverted later)
      vlabs$y <- vlabs$x
      vlabs$x <- -0.3
      x <- vSeg$x
      y <- vSeg$y
      vSeg$y <- x
      vSeg$x <- y
      xend <- vSeg$xend
      yend <- vSeg$yend
      vSeg$yend <- xend
      vSeg$xend <- yend
      # Adjust width/height
      # - Vertical dendrogram
      vnch <- Width*0.07*max(nchar(vlabs$label))/12
      xmn <- min(c(vSeg$x, vSeg$xend))
      xmx <- max(c(vSeg$x, vSeg$xend))
      vSeg$x <- -(vSeg$x - xmn)*Width*0.07/xmx - 1.5 - vnch
      vSeg$xend <- -(vSeg$xend - xmn)*Width*0.07/xmx - 1.5 - vnch
      # - Horizontal dendrogram
      hnch <- Height*0.07*max(nchar(hlabs$label))/800
      ymn <- min(c(hSeg$y, hSeg$yend))
      ymx <- max(c(hSeg$y, hSeg$yend))
      hSeg$y <- Height + hnch + 1.5 + (hSeg$y - ymn)*Height*0.07/ymx
      hSeg$yend <- Height + hnch + 1.5 + (hSeg$yend - ymn)*Height*0.07/ymx
      # Order labels by order of appearance
      hlabs <- hlabs[order(hlabs$x, decreasing = FALSE),]
      vlabs <- vlabs[order(vlabs$y, decreasing = FALSE),]
      # Re-order our matrix based on extracted dendrogram labels
      temp <- temp[, match(vlabs$label, colnames(temp))]
      temp <- temp[match(hlabs$label, rownames(temp)),]
      imputed <- imputed[, match(vlabs$label, colnames(imputed))]
      imputed <- imputed[match(hlabs$label, rownames(imputed)),]
      # Re-introduce missing values
      MaxChar <- 13
      hlabs$label2 <- hlabs$label
      w <- which(nchar(hlabs$label2) > MaxChar)
      hlabs$label2[w] <- paste0(substr(hlabs$label2[w], 1, MaxChar-3), "...")
      # Create heatmap
      temp$Rowname <- row.names(temp)
      temp2 <- magrittr::set_colnames(reshape2::melt(temp, id.vars = "Rowname"), c("Label", "Sample", "value"))
      temp2$Label <- as.character(temp2$Label)
      temp2$Sample <- as.character(temp2$Sample)
      temp2$Xmax <- match(temp2$Label, hlabs$label) # Explicitly should be the case now!
      temp2$label2 <- hlabs$label2[temp2$Xmax]
      temp2$Xmin <- temp2$Xmax-1
      temp2$Ymax <- vlabs$y[match(temp2$Sample, vlabs$label)]
      temp2$Ymin <- temp2$Ymax-1
      w1 <- which(temp2$Colour == "green")
      w2 <- which((temp2$Ymin == max(temp2$Ymin))&(temp2$Colour == "green"))
      # Color and fill scales
      wV <- unique(ceiling(c(1:NVClust)*MaxVClust/NVClust))
      wH <- unique(ceiling(c(1:NHClust)*MaxHClust/NHClust))
      vClScl <- setNames(VClustScl[wV], 1:length(wV))
      hClScl <- setNames(HClustScl[wH], 1:length(wH))
      VcolScale <- scale_color_manual(name = "Samples cluster", values = vClScl)
      VfillScale <- scale_fill_manual(name = "Samples cluster", values = vClScl)
      HcolScale <- scale_color_manual(name = "Protein groups cluster", values = hClScl)
      HfillScale <- scale_fill_manual(name = "Protein groups cluster", values = hClScl)
      # Create heatmap plot
      Xlim <- c(NA, Width)
      Ylim <- c(-10, max(c(max(hSeg$y) + Height*0.6), 20))
      #
      prot.list.marks <- FALSE
      if (prot.list.Cond) {
        w0 <- which(temp2$Ymin == 0)
        temp2$`Histone(s)` <- pep$`Histone(s)`[match(temp2$Label, pep$Label)]
        g <- which(temp2$`Histone(s)` != "")
        #tst <- unlist(strsplit(temp2$"Leading protein IDs"[w0], ";"))[1]
        #g <- grsep(tst, x = temp2$"Leading protein IDs"[w0])
        if (length(g)) {
          prot.list.marks <- TRUE
          Ylim[1] <- -20
          temp2c <- temp2[w0[g], , drop = FALSE]
        }
      }
      # Main data
      temp2a <- temp2[, c("Xmin", "Ymin", "value", "Label", "Sample")]
      # Colour scale
      temp2b <- data.frame(Xmin = 0:round(Width*0.1),
                           Ymin = Ylim[2]*0.8)
      Mn <- min(temp2a$value, na.rm = TRUE)
      Mx <- max(temp2a$value, na.rm = TRUE)
      temp2b$value <- Mn + temp2b$Xmin*(Mx-Mn)/max(temp2b$Xmin)
      temp2b$Xmin <- temp2b$Xmin-Width*0.15
      temp2b$Label <- temp2b$Sample <- NA
      w2a <- 1:nrow(temp2a)
      w2b <- 1:nrow(temp2b) + max(w2a)
      temp2a <- rbind(temp2a, temp2b)
      # Samples-level: how well do clusters fit expectations
      SamplesClust <- vlabs[, c("label", "Cluster")]
      SamplesClust$Group <- as.factor(smplsMap$Group[match(SamplesClust$label, smplsMap$New)])
      SamplesClust$Cluster <- as.factor(paste0("Cluster", as.character(SamplesClust$Cluster)))
      tstSmplClust <- table(SamplesClust$Group, SamplesClust$Cluster)
      ClustChiSqTst <- suppressWarnings(chisq.test(tstSmplClust))
      #
      xCntr <- Width*0.6
      yScale <- Height*2
      nm <- paste0("Clust. heatmap", normTypeInsrt, fltInsrt)
      GrLab <- data.frame(label = c(nm,
                                    "Sample",
                                    paste0("Chi-squared contingency test P-value: ", round(ClustChiSqTst$p.value, 5)),
                                    "Protein group",
                                    "Min",
                                    "Max"),
                          x = c(xCntr,
                                min(vSeg$x)-Width*0.11,
                                min(vSeg$x)-Width*0.095,
                                xCntr,
                                min(temp2b$Xmin),
                                max(temp2b$Xmin)),
                          y = c(max(c(hSeg$y, hSeg$yend)) + yScale*0.15,
                                Height*0.5,
                                Height*0.5,
                                max(c(hSeg$y, hSeg$yend)) + yScale*0.1,
                                temp2b$Ymin[1]-1,
                                temp2b$Ymin[1]-1),
                          angle = c(0, 90, 90, 0, 0, 0),
                          size = c(5, 4, 3, 4, 3, 3),
                          fontface = c("bold", "plain", "italic", "plain", "plain", "plain"))
      Xlim[1] <- min(c(vSeg$x, vSeg$xend))-Width*0.15
      Ylim[1] <- min(c(Ylim[1], min(temp2a$Ymin)))
      Xlim[2] <- max(c(Xlim[2], max(temp2a$Xmin)+1))
      Ylim[2] <- max(c(Ylim[2], max(temp2a$Ymin)+1))
      xCntr <- mean(Xlim)
      yCntr <- mean(Ylim)
      yScale <- Ylim[2]-Ylim[1]
      #
      # Create graph
      heatmap.plot <- ggplot(temp2a[w2a,]) +
        geom_rect(aes(xmin = Xmin, xmax = Xmin+1, ymin = Ymin, ymax = Ymin+1, fill = value, text = Label)) +
        geom_rect(data = temp2a[w2b,], aes(xmin = Xmin, xmax = Xmin+1, ymin = Ymin, ymax = Ymin+1, fill = value)) +
        theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), 
              axis.text.y = element_blank(), axis.ticks.y = element_blank(), 
              panel.background = element_rect(fill = "transparent", color = NA),
              plot.margin = margin(0, 0, 0, 0, "cm")) +
        #scale_fill_gradient2(low = "darkblue", mid = "lightgrey", high = "darkred") +
        scale_fill_viridis(option = "D") +
        xlab(NULL) + ylab(NULL) + theme(legend.position = "none") +
        xlim(Xlim[1], Xlim[2]) + ylim(Ylim[1], Ylim[2])
      #poplot(heatmap.plot, 12, 20)
      # heatmap.plot <- heatmap.plot + 
      #   geom_text(data = temp2a[which(temp2a$Xmin == min(temp2$Xmin)),],
      #             aes(x = Xmin, y = Ymin, label = Sample))
      # Title, axis labels, colour scale annotations
      #
      # Add labels and dendrograms:
      # - Title, scale, chi-squared test
      heatmap.plot <- heatmap.plot +
        new_scale("size") + scale_size_identity() +
        geom_text(data = GrLab, aes(label = label, x = x, y = y, angle = angle, size = size, fontface = fontface),
                  color = "black", hjust = 0.5)
      #poplot(heatmap.plot, 12, 20)
      # - Cluster boxes
      heatmap.plot <- heatmap.plot + new_scale_color() + HcolScale
      if (KlustMeth == 2) {
        Clutst <- aggregate(hlabs$x, list(hlabs$Cluster), function(x) { min(x)-1 })
        colnames(Clutst)[1] <- "Cluster"
        Clutst$xend <- aggregate(hlabs$x, list(hlabs$Cluster), max)$x
        Clutst$mid <- (Clutst$xend+Clutst$x)/2
        heatmap.plot <- heatmap.plot +
          geom_rect(data = Clutst, aes(xmin = x, xmax = xend, colour = Cluster),
                    ymin = 0, ymax = Height, fill = NA) +
          geom_text(data = Clutst, aes(x = mid, label = Cluster, colour = Cluster),
                    y = Height/2, hjust = 0.5, vjust = 0.5, cex = 5)
        #poplot(heatmap.plot2, 12, 20)
      }
      #poplot(heatmap.plot, 12, 20)
      # - Horizontal dendrogram and protein  names
      heatmap.plot <- heatmap.plot +
        geom_segment(data = hSeg, linewidth = 0.5,
                     aes(x = x, y = y, xend = xend, yend = yend)) +
        geom_text(data = hlabs, aes(x = x-0.5, label = label2, colour = Cluster),
                  y = Height+0.05, angle = 90, cex = 0.5, hjust = 0, vjust = 0)
      # - Vertical dendrogram and sample names
      heatmap.plot <- heatmap.plot +
        geom_segment(data = vSeg, linewidth = 0.5,
                     aes(x = x, y = y - 0.5, xend = xend, yend = yend - 0.5)) +
        new_scale_color() + VcolScale +
        geom_text(data = vlabs, aes(y = y - 0.5, label = label, colour = Cluster),
                  x = -0.5, hjust = 1, vjust = 0.5, cex = 2.5)
      # - Proteins of interest
      if (prot.list.marks) {
        heatmap.plot <- heatmap.plot +
          geom_point(data = temp2c, aes(x = Xmin+0.5), y = -0.5, colour = "red", fill = "red", shape = 17) +
          geom_text(data = temp2c, aes(x = Xmin+0.5, label = label2),
                    y = -1, colour = "red", angle = -60, hjust = 0, cex = 2)
      }
      #poplot(heatmap.plot, 12, 20)
      ggsave(paste0(dir, "/", nm, ".jpeg"), heatmap.plot)
      ggsave(paste0(dir, "/", nm, ".pdf"), heatmap.plot)
      #
      # Plotly version
      tempLy <- temp2a[w2a,]
      tempLy$Sample <- factor(temp2$Sample, levels = smpls)
      ##tempLy$Ymin <- tempLy$Ymin+0.5
      plotleatmap <- plot_ly(data = tempLy, x = ~Xmin, y = ~Ymin, z = ~value, type = "heatmap", hovertext = tempLy$Label)
      # I cannot find a way to remove tick marks!!!!!
      plLyV <- vSeg
      ##plLyV$x <- -Width*0.2-plLyV$x 
      ##plLyV$xend <- -Width*0.2-plLyV$xend
      plLyV$y <- plLyV$y-1
      plLyV$yend <- plLyV$yend-1 
      plotleatmap <- add_segments(plotleatmap, x = ~x, xend = ~xend, y = ~y, yend = ~yend,
                                  data = plLyV, inherit = FALSE, color = I("black"),
                                  showlegend = FALSE)
      plLyH <- hSeg
      ##plLyH$x <- plLyH$x-0.5
      ##plLyH$xend <- plLyH$xend-0.5
      plLyH$y <- plLyH$y - hnch - 1.5
      plLyH$yend <- plLyH$yend - hnch - 1.5
      plotleatmap <- add_segments(plotleatmap, x = ~x, xend = ~xend, y = ~y, yend = ~yend,
                                  data = plLyH, inherit = FALSE, color = I("black"),
                                  showlegend = FALSE)
      if (KlustMeth == 2) { # Cluster shapes do not appear to work
        plotleatmap <- add_segments(plotleatmap, x = ~ x, xend = ~ xend,
                                    y = I(-0.2*as.numeric(Clutst$Cluster))-1,
                                    yend = I(-0.2*as.numeric(Clutst$Cluster))-1, data = Clutst,
                                    inherit = FALSE, color = ~ Cluster, showlegend = FALSE)
      }
      vlabs2 <- vlabs
      vlabs2$x <- -vnch/2
      vlabs2$y <- vlabs2$y-1
      plotleatmap <- add_trace(plotleatmap, data = vlabs2, y = ~y, x = ~x, text = ~label,
                               color = I("black"), inherit = FALSE, type = "scatter",
                               mode = "text", showlegend = FALSE)
      plotleatmap <- layout(plotleatmap, title = nm,
                            xaxis = list(title = "Protein groups",
                                         tickmode = "array", tickvals = NULL, showticklabels = FALSE, showgrid = FALSE, zeroline = FALSE),
                            yaxis = list(title = "Samples",
                                         tickmode = "array", tickvals = NULL, showticklabels = FALSE, showgrid = FALSE, zeroline = FALSE))
      if ((prot.list.marks)&&(flt == "Global")) {
        temp2c$X <- (temp2c$Xmin+temp2c$Xmax)/2
        plotleatmap <- add_trace(plotleatmap, data = temp2c, y = I(-0.501), x = ~X,
                                 text = ~Label, color = ~Label, inherit = FALSE,
                                 type = "scatter", mode = "markers", showlegend = FALSE)
      }
      htmlwidgets::saveWidget(plotleatmap, paste0(dir, "/", nm, ".html"))
      system(paste0("open \"", dir, "/", nm, ".html\""))
      plotLeatMaps[[normType]][[flt]] <- plotleatmap
    }
  }
}
invisible(parLapply(parClust, 1:N.clust, function(x) { rm(list = ls());gc() }))
# Save modifications table
tmp <- Modifs
tmp$Site_long <- NULL
tmp$Site <- NULL
tmp$origMark <- NULL
for (k in colnames(tmp)) {
  if (typeof(tmp[[k]]) == "list") { tmp[[k]] <- vapply(tmp[[k]], paste, "", collapse = ";") }
}
write.csv(tmp, paste0(dstDir, "/Mods table.csv"), row.names = FALSE)

# Done!
ScriptPath <- normalizePath(gtools::script_file(), winslash = "/")
if (dirname(ScriptPath) != dstDir) { file.copy(ScriptPath, dstDir, overwrite = TRUE) }
saveImgFun(backupFl)
openwd(dstDir)
